<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Logistic regression | Analytics with KNIME and R</title>
  <meta name="description" content="This is a draft." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Logistic regression | Analytics with KNIME and R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a draft." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Logistic regression | Analytics with KNIME and R" />
  
  <meta name="twitter:description" content="This is a draft." />
  

<meta name="author" content="F Acito" />


<meta name="date" content="2021-11-16" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="multiple-regression.html"/>
<link rel="next" href="ensemble-models.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Cover page</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#what-is-analytics"><i class="fa fa-check"></i><b>1.1</b> What is analytics?</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#some-trends-in-analytics"><i class="fa fa-check"></i><b>1.2</b> Some trends in analytics</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="intro.html"><a href="intro.html#broadening-of-application-areas"><i class="fa fa-check"></i><b>1.2.1</b> Broadening of application areas</a></li>
<li class="chapter" data-level="1.2.2" data-path="intro.html"><a href="intro.html#generalization-of-the-notion-of-data"><i class="fa fa-check"></i><b>1.2.2</b> Generalization of the notion of data</a></li>
<li class="chapter" data-level="1.2.3" data-path="intro.html"><a href="intro.html#a-trend-from-slicing-and-dicing-data-to-more-advanced-techniques"><i class="fa fa-check"></i><b>1.2.3</b> A trend from “slicing and dicing” data to more advanced techniques</a></li>
<li class="chapter" data-level="1.2.4" data-path="intro.html"><a href="intro.html#more-advanced-data-visualization"><i class="fa fa-check"></i><b>1.2.4</b> More advanced data visualization</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#the-analytics-process-model"><i class="fa fa-check"></i><b>1.3</b> The analytics process model</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html"><i class="fa fa-check"></i><b>2</b> Business understanding and problem definition</a>
<ul>
<li class="chapter" data-level="2.1" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html#expert-views"><i class="fa fa-check"></i><b>2.1</b> Expert views</a></li>
<li class="chapter" data-level="2.2" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html#understanding-the-business"><i class="fa fa-check"></i><b>2.2</b> Understanding the business</a></li>
<li class="chapter" data-level="2.3" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html#identifying-stakeholders"><i class="fa fa-check"></i><b>2.3</b> Identifying stakeholders</a></li>
<li class="chapter" data-level="2.4" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html#structured-versus-unstructured-problems"><i class="fa fa-check"></i><b>2.4</b> Structured versus unstructured problems</a></li>
<li class="chapter" data-level="2.5" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html#framing-the-problem"><i class="fa fa-check"></i><b>2.5</b> Framing the problem</a></li>
<li class="chapter" data-level="2.6" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html#summary"><i class="fa fa-check"></i><b>2.6</b> Summary</a></li>
<li class="chapter" data-level="" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html#appendix-some-tools-for-problem-definition"><i class="fa fa-check"></i>Appendix: Some tools for problem definition</a>
<ul>
<li class="chapter" data-level="" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html#right-to-left-thinking"><i class="fa fa-check"></i>Right to left thinking</a></li>
<li class="chapter" data-level="" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html#reversing-the-problem"><i class="fa fa-check"></i>Reversing the problem</a></li>
<li class="chapter" data-level="" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html#open-the-problem-with-whys"><i class="fa fa-check"></i>Open the problem with “whys”</a></li>
<li class="chapter" data-level="" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html#challenge-assumptions"><i class="fa fa-check"></i>Challenge assumptions</a></li>
<li class="chapter" data-level="" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html#chunking"><i class="fa fa-check"></i>Chunking</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html#problems"><i class="fa fa-check"></i>Problems</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introduction-to-knime.html"><a href="introduction-to-knime.html"><i class="fa fa-check"></i><b>3</b> Introduction to KNIME</a>
<ul>
<li class="chapter" data-level="3.1" data-path="introduction-to-knime.html"><a href="introduction-to-knime.html#the-knime-workbench"><i class="fa fa-check"></i><b>3.1</b> The KNIME Workbench</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="introduction-to-knime.html"><a href="introduction-to-knime.html#elements-of-the-knime-workbench"><i class="fa fa-check"></i><b>3.1.1</b> Elements of the KNIME Workbench</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="introduction-to-knime.html"><a href="introduction-to-knime.html#learning-to-use-knime"><i class="fa fa-check"></i><b>3.2</b> Learning to use KNIME</a></li>
<li class="chapter" data-level="3.3" data-path="introduction-to-knime.html"><a href="introduction-to-knime.html#knime-extensions-and-integrations"><i class="fa fa-check"></i><b>3.3</b> KNIME extensions and integrations</a></li>
<li class="chapter" data-level="3.4" data-path="introduction-to-knime.html"><a href="introduction-to-knime.html#knime-workflow-example-1-predicting-heart-disease"><i class="fa fa-check"></i><b>3.4</b> KNIME workflow example #1: Predicting heart disease</a></li>
<li class="chapter" data-level="3.5" data-path="introduction-to-knime.html"><a href="introduction-to-knime.html#knime-workflow-example-2-preparation-of-hospital-data"><i class="fa fa-check"></i><b>3.5</b> KNIME workflow example #2: Preparation of hospital data</a></li>
<li class="chapter" data-level="3.6" data-path="introduction-to-knime.html"><a href="introduction-to-knime.html#summary-1"><i class="fa fa-check"></i><b>3.6</b> Summary</a></li>
<li class="chapter" data-level="" data-path="introduction-to-knime.html"><a href="introduction-to-knime.html#problems-1"><i class="fa fa-check"></i>Problems</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-preparation.html"><a href="data-preparation.html"><i class="fa fa-check"></i><b>4</b> Data preparation</a>
<ul>
<li class="chapter" data-level="4.1" data-path="data-preparation.html"><a href="data-preparation.html#introduction"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="data-preparation.html"><a href="data-preparation.html#obtaining-the-needed-data"><i class="fa fa-check"></i><b>4.2</b> Obtaining the needed data</a></li>
<li class="chapter" data-level="4.3" data-path="data-preparation.html"><a href="data-preparation.html#data-cleaning"><i class="fa fa-check"></i><b>4.3</b> Data cleaning</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="data-preparation.html"><a href="data-preparation.html#missing-values"><i class="fa fa-check"></i><b>4.3.1</b> Missing values</a></li>
<li class="chapter" data-level="4.3.2" data-path="data-preparation.html"><a href="data-preparation.html#outliers"><i class="fa fa-check"></i><b>4.3.2</b> Outliers</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="data-preparation.html"><a href="data-preparation.html#feature-engineering"><i class="fa fa-check"></i><b>4.4</b> Feature engineering</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="data-preparation.html"><a href="data-preparation.html#data-transformations"><i class="fa fa-check"></i><b>4.4.1</b> Data transformations</a></li>
<li class="chapter" data-level="4.4.2" data-path="data-preparation.html"><a href="data-preparation.html#data-exploration"><i class="fa fa-check"></i><b>4.4.2</b> Data exploration</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="principal-components-analytics.html"><a href="principal-components-analytics.html"><i class="fa fa-check"></i><b>5</b> Principal components analytics</a>
<ul>
<li class="chapter" data-level="5.1" data-path="principal-components-analytics.html"><a href="principal-components-analytics.html#approaches-to-dimension-reduction"><i class="fa fa-check"></i><b>5.1</b> Approaches to dimension reduction</a></li>
<li class="chapter" data-level="5.2" data-path="principal-components-analytics.html"><a href="principal-components-analytics.html#description"><i class="fa fa-check"></i><b>5.2</b> Description</a></li>
<li class="chapter" data-level="5.3" data-path="principal-components-analytics.html"><a href="principal-components-analytics.html#the-pca-model"><i class="fa fa-check"></i><b>5.3</b> The PCA model</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="evaluating-predictive-models.html"><a href="evaluating-predictive-models.html"><i class="fa fa-check"></i><b>6</b> Evaluating predictive models</a>
<ul>
<li class="chapter" data-level="6.1" data-path="evaluating-predictive-models.html"><a href="evaluating-predictive-models.html#introduction-1"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="evaluating-predictive-models.html"><a href="evaluating-predictive-models.html#training-testing-and-validation-samples"><i class="fa fa-check"></i><b>6.2</b> Training, Testing, and Validation samples</a></li>
<li class="chapter" data-level="6.3" data-path="evaluating-predictive-models.html"><a href="evaluating-predictive-models.html#evaluating-continuous-versus-discrete-targets"><i class="fa fa-check"></i><b>6.3</b> Evaluating continuous versus discrete targets</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="evaluating-predictive-models.html"><a href="evaluating-predictive-models.html#evaluating-performance-with-continuous-targets"><i class="fa fa-check"></i><b>6.3.1</b> Evaluating performance with continuous targets</a></li>
<li class="chapter" data-level="6.3.2" data-path="evaluating-predictive-models.html"><a href="evaluating-predictive-models.html#evaluating-performance-with-classification-models"><i class="fa fa-check"></i><b>6.3.2</b> Evaluating performance with classification models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="multiple-regression.html"><a href="multiple-regression.html"><i class="fa fa-check"></i><b>7</b> Multiple regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="multiple-regression.html"><a href="multiple-regression.html#introduction-2"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="multiple-regression.html"><a href="multiple-regression.html#regression-techniques"><i class="fa fa-check"></i><b>7.2</b> Regression techniques</a></li>
<li class="chapter" data-level="7.3" data-path="multiple-regression.html"><a href="multiple-regression.html#regression-for-explanation"><i class="fa fa-check"></i><b>7.3</b> Regression for explanation</a></li>
<li class="chapter" data-level="7.4" data-path="multiple-regression.html"><a href="multiple-regression.html#regression-for-prediction"><i class="fa fa-check"></i><b>7.4</b> Regression for prediction</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="multiple-regression.html"><a href="multiple-regression.html#revisiting-regression-assumptions"><i class="fa fa-check"></i><b>7.4.1</b> Revisiting regression assumptions</a></li>
<li class="chapter" data-level="7.4.2" data-path="multiple-regression.html"><a href="multiple-regression.html#prediction-example-used-toyota-corollas"><i class="fa fa-check"></i><b>7.4.2</b> Prediction example: Used Toyota Corollas</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="multiple-regression.html"><a href="multiple-regression.html#appendix-a-brief-history-of-regression"><i class="fa fa-check"></i>Appendix: A brief history of regression</a></li>
<li class="chapter" data-level="" data-path="multiple-regression.html"><a href="multiple-regression.html#problems-2"><i class="fa fa-check"></i>Problems</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>8</b> Logistic regression</a>
<ul>
<li class="chapter" data-level="8.1" data-path="logistic-regression.html"><a href="logistic-regression.html#example-with-a-single-predictor"><i class="fa fa-check"></i><b>8.1</b> Example with a single predictor</a></li>
<li class="chapter" data-level="8.2" data-path="logistic-regression.html"><a href="logistic-regression.html#example-predictive-analytic-in-hr"><i class="fa fa-check"></i><b>8.2</b> Example: Predictive analytic in HR</a></li>
<li class="chapter" data-level="8.3" data-path="logistic-regression.html"><a href="logistic-regression.html#predictor-interpretation-and-importance"><i class="fa fa-check"></i><b>8.3</b> Predictor interpretation and importance</a></li>
<li class="chapter" data-level="8.4" data-path="logistic-regression.html"><a href="logistic-regression.html#regularized-logistic-regression"><i class="fa fa-check"></i><b>8.4</b> Regularized logistic regression</a></li>
<li class="chapter" data-level="8.5" data-path="logistic-regression.html"><a href="logistic-regression.html#probability-calibration"><i class="fa fa-check"></i><b>8.5</b> Probability calibration</a></li>
<li class="chapter" data-level="8.6" data-path="logistic-regression.html"><a href="logistic-regression.html#evaluation-of-logistic-regression"><i class="fa fa-check"></i><b>8.6</b> Evaluation of logistic regression</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ensemble-models.html"><a href="ensemble-models.html"><i class="fa fa-check"></i><b>9</b> Ensemble models</a>
<ul>
<li class="chapter" data-level="9.1" data-path="ensemble-models.html"><a href="ensemble-models.html#creating-ensemble-models"><i class="fa fa-check"></i><b>9.1</b> Creating ensemble models</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="ensemble-models.html"><a href="ensemble-models.html#reduced-variation"><i class="fa fa-check"></i><b>9.1.1</b> Reduced variation</a></li>
<li class="chapter" data-level="9.1.2" data-path="ensemble-models.html"><a href="ensemble-models.html#improved-performance"><i class="fa fa-check"></i><b>9.1.2</b> Improved performance</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="ensemble-models.html"><a href="ensemble-models.html#parallel-and-sequential-learners"><i class="fa fa-check"></i><b>9.2</b> Parallel and sequential learners</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="ensemble-models.html"><a href="ensemble-models.html#bagging-bootstrap-aggregating"><i class="fa fa-check"></i><b>9.2.1</b> Bagging (Bootstrap Aggregating)</a></li>
<li class="chapter" data-level="9.2.2" data-path="ensemble-models.html"><a href="ensemble-models.html#random-forests"><i class="fa fa-check"></i><b>9.2.2</b> Random Forests</a></li>
<li class="chapter" data-level="9.2.3" data-path="ensemble-models.html"><a href="ensemble-models.html#adaboost"><i class="fa fa-check"></i><b>9.2.3</b> AdaBoost</a></li>
<li class="chapter" data-level="9.2.4" data-path="ensemble-models.html"><a href="ensemble-models.html#gradient-boosting-machines"><i class="fa fa-check"></i><b>9.2.4</b> Gradient Boosting Machines</a></li>
<li class="chapter" data-level="9.2.5" data-path="ensemble-models.html"><a href="ensemble-models.html#xgboost"><i class="fa fa-check"></i><b>9.2.5</b> XGBoost</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="ensemble-models.html"><a href="ensemble-models.html#example-of-ensemble-modeling-for-a-continuous-target"><i class="fa fa-check"></i><b>9.3</b> Example of ensemble modeling for a continuous target</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="naive-bayes.html"><a href="naive-bayes.html"><i class="fa fa-check"></i><b>10</b> Naive Bayes</a>
<ul>
<li class="chapter" data-level="10.1" data-path="naive-bayes.html"><a href="naive-bayes.html#a-thought-problem"><i class="fa fa-check"></i><b>10.1</b> A thought problem</a></li>
<li class="chapter" data-level="10.2" data-path="naive-bayes.html"><a href="naive-bayes.html#bayes-theorem-applied-to-predictive-analytics"><i class="fa fa-check"></i><b>10.2</b> Bayes Theorem applied to predictive analytics</a></li>
<li class="chapter" data-level="10.3" data-path="naive-bayes.html"><a href="naive-bayes.html#illustration-of-naïve-bayes-with-a-toy-data-set"><i class="fa fa-check"></i><b>10.3</b> Illustration of Naïve Bayes with a “toy” data set</a></li>
<li class="chapter" data-level="10.4" data-path="naive-bayes.html"><a href="naive-bayes.html#the-assumption-of-conditional-independence"><i class="fa fa-check"></i><b>10.4</b> The assumption of conditional independence</a></li>
<li class="chapter" data-level="10.5" data-path="naive-bayes.html"><a href="naive-bayes.html#naïve-bayes-with-continuous-predictors"><i class="fa fa-check"></i><b>10.5</b> Naïve Bayes with continuous predictors</a></li>
<li class="chapter" data-level="10.6" data-path="naive-bayes.html"><a href="naive-bayes.html#laplace-smoothing"><i class="fa fa-check"></i><b>10.6</b> Laplace Smoothing</a></li>
<li class="chapter" data-level="10.7" data-path="naive-bayes.html"><a href="naive-bayes.html#example-using-naïve-bayes-with-churn-data"><i class="fa fa-check"></i><b>10.7</b> Example using naïve Bayes with churn data</a></li>
<li class="chapter" data-level="10.8" data-path="naive-bayes.html"><a href="naive-bayes.html#spam-detection-using-naïve-bayes"><i class="fa fa-check"></i><b>10.8</b> Spam detection using naïve Bayes</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="deep-learning.html"><a href="deep-learning.html"><i class="fa fa-check"></i><b>11</b> Deep learning</a></li>
<li class="chapter" data-level="12" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html"><i class="fa fa-check"></i><b>12</b> k Nearest Neighbors</a>
<ul>
<li class="chapter" data-level="12.1" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#k-nearest-neighbors-and-memory-based-learning"><i class="fa fa-check"></i><b>12.1</b> k nearest neighbors and memory-based learning</a></li>
<li class="chapter" data-level="12.2" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#typical-applications"><i class="fa fa-check"></i><b>12.2</b> Typical applications</a></li>
<li class="chapter" data-level="12.3" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#what-is-knn"><i class="fa fa-check"></i><b>12.3</b> What is kNN?</a></li>
<li class="chapter" data-level="12.4" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#a-two-dimensional-graphic-example-of-knn"><i class="fa fa-check"></i><b>12.4</b> A two-dimensional graphic example of kNN</a></li>
<li class="chapter" data-level="12.5" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#example-of-knn-diagnosing-heart-disease"><i class="fa fa-check"></i><b>12.5</b> Example of kNN: Diagnosing heart disease</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#results"><i class="fa fa-check"></i><b>12.5.1</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#knn-for-continuous-targets"><i class="fa fa-check"></i><b>12.6</b> kNN for continuous targets</a></li>
<li class="chapter" data-level="12.7" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#knn-for-multiclass-target-variables"><i class="fa fa-check"></i><b>12.7</b> kNN for multiclass target variables</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="tree-models.html"><a href="tree-models.html"><i class="fa fa-check"></i><b>13</b> Tree models</a>
<ul>
<li class="chapter" data-level="13.1" data-path="tree-models.html"><a href="tree-models.html#classification-trees"><i class="fa fa-check"></i><b>13.1</b> Classification trees</a></li>
<li class="chapter" data-level="13.2" data-path="tree-models.html"><a href="tree-models.html#forming-classification-trees"><i class="fa fa-check"></i><b>13.2</b> Forming classification trees</a></li>
<li class="chapter" data-level="13.3" data-path="tree-models.html"><a href="tree-models.html#varieties-of-classification-tree-algorithms"><i class="fa fa-check"></i><b>13.3</b> Varieties of classification tree algorithms</a></li>
<li class="chapter" data-level="13.4" data-path="tree-models.html"><a href="tree-models.html#criteria-for-splitting-and-growing-a-tree"><i class="fa fa-check"></i><b>13.4</b> Criteria for splitting and growing a tree</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="tree-models.html"><a href="tree-models.html#the-gini-index"><i class="fa fa-check"></i><b>13.4.1</b> The Gini index</a></li>
<li class="chapter" data-level="13.4.2" data-path="tree-models.html"><a href="tree-models.html#information-gain"><i class="fa fa-check"></i><b>13.4.2</b> Information Gain</a></li>
<li class="chapter" data-level="13.4.3" data-path="tree-models.html"><a href="tree-models.html#chi-square-as-a-splitting-criterion"><i class="fa fa-check"></i><b>13.4.3</b> Chi-square as a splitting criterion</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="tree-models.html"><a href="tree-models.html#overfitting"><i class="fa fa-check"></i><b>13.5</b> Overfitting</a></li>
<li class="chapter" data-level="13.6" data-path="tree-models.html"><a href="tree-models.html#example-of-a-classification-tree"><i class="fa fa-check"></i><b>13.6</b> Example of a classification tree</a></li>
<li class="chapter" data-level="13.7" data-path="tree-models.html"><a href="tree-models.html#regression-trees"><i class="fa fa-check"></i><b>13.7</b> Regression trees</a>
<ul>
<li class="chapter" data-level="13.7.1" data-path="tree-models.html"><a href="tree-models.html#how-regression-trees-work"><i class="fa fa-check"></i><b>13.7.1</b> How regression trees work</a></li>
<li class="chapter" data-level="13.7.2" data-path="tree-models.html"><a href="tree-models.html#example-predicting-home-prices"><i class="fa fa-check"></i><b>13.7.2</b> Example: Predicting home prices</a></li>
</ul></li>
<li class="chapter" data-level="13.8" data-path="tree-models.html"><a href="tree-models.html#strengths-and-weaknesses"><i class="fa fa-check"></i><b>13.8</b> Strengths and weaknesses</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="neural-networks.html"><a href="neural-networks.html"><i class="fa fa-check"></i><b>14</b> Neural networks</a>
<ul>
<li class="chapter" data-level="14.1" data-path="neural-networks.html"><a href="neural-networks.html#what-are-artificial-neural-networks"><i class="fa fa-check"></i><b>14.1</b> What are artificial neural networks?</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="neural-networks.html"><a href="neural-networks.html#human-neurons-to-mathematical-models"><i class="fa fa-check"></i><b>14.1.1</b> Human neurons to mathematical models</a></li>
<li class="chapter" data-level="14.1.2" data-path="neural-networks.html"><a href="neural-networks.html#activation-functions"><i class="fa fa-check"></i><b>14.1.2</b> Activation functions</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="neural-networks.html"><a href="neural-networks.html#the-road-to-machine-learning-with-neural-nets"><i class="fa fa-check"></i><b>14.2</b> The road to machine learning with neural nets</a></li>
<li class="chapter" data-level="14.3" data-path="neural-networks.html"><a href="neural-networks.html#example-of-a-neural-network"><i class="fa fa-check"></i><b>14.3</b> Example of a neural network</a></li>
<li class="chapter" data-level="14.4" data-path="neural-networks.html"><a href="neural-networks.html#training-a-neural-net"><i class="fa fa-check"></i><b>14.4</b> Training a neural net</a></li>
<li class="chapter" data-level="14.5" data-path="neural-networks.html"><a href="neural-networks.html#considerations-in-using-neural-nets"><i class="fa fa-check"></i><b>14.5</b> Considerations in using neural nets</a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="neural-networks.html"><a href="neural-networks.html#missing-data"><i class="fa fa-check"></i><b>14.5.1</b> Missing data</a></li>
<li class="chapter" data-level="14.5.2" data-path="neural-networks.html"><a href="neural-networks.html#representative-data"><i class="fa fa-check"></i><b>14.5.2</b> Representative data</a></li>
<li class="chapter" data-level="14.5.3" data-path="neural-networks.html"><a href="neural-networks.html#all-eventualities-must-be-covered"><i class="fa fa-check"></i><b>14.5.3</b> All eventualities must be covered</a></li>
<li class="chapter" data-level="14.5.4" data-path="neural-networks.html"><a href="neural-networks.html#unbalanced-data-sets"><i class="fa fa-check"></i><b>14.5.4</b> Unbalanced data sets</a></li>
<li class="chapter" data-level="14.5.5" data-path="neural-networks.html"><a href="neural-networks.html#the-overfitting-problem"><i class="fa fa-check"></i><b>14.5.5</b> The overfitting problem</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="neural-networks.html"><a href="neural-networks.html#neural-network-example"><i class="fa fa-check"></i><b>14.6</b> Neural network example</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="cluster-analysis.html"><a href="cluster-analysis.html"><i class="fa fa-check"></i><b>15</b> Cluster analysis</a>
<ul>
<li class="chapter" data-level="15.1" data-path="cluster-analysis.html"><a href="cluster-analysis.html#approaches-to-forming-clusters"><i class="fa fa-check"></i><b>15.1</b> Approaches to forming clusters</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="cluster-analysis.html"><a href="cluster-analysis.html#hierarchical-versus-partitioning-methods"><i class="fa fa-check"></i><b>15.1.1</b> Hierarchical versus partitioning methods</a></li>
<li class="chapter" data-level="15.1.2" data-path="cluster-analysis.html"><a href="cluster-analysis.html#hard-versus-soft-methods"><i class="fa fa-check"></i><b>15.1.2</b> “Hard” versus “soft” methods</a></li>
<li class="chapter" data-level="15.1.3" data-path="cluster-analysis.html"><a href="cluster-analysis.html#applying-hierarchical-clusters"><i class="fa fa-check"></i><b>15.1.3</b> Applying hierarchical clusters</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Analytics with KNIME and R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="logistic-regression" class="section level1" number="8">
<h1><span class="header-section-number">Chapter 8</span> Logistic regression</h1>
<p>Many analytics problems can be expressed as the prediction of which of two outcomes is more likely. The target variable in such applications is binary and expressed as “1” or “0.” There are many questions with a binary outcome, such as:</p>
<ul>
<li>Buy/Not buy.</li>
<li>Success/Failure.</li>
<li>Heart attack/No heart attack.</li>
<li>Continue/Not continue.</li>
<li>Fraud/No fraud.</li>
<li>Cancer/No cancer.</li>
<li>Vote yes/Yote no.</li>
</ul>
<p>This, of course, is just a partial list since binary outcomes are of concern in many different disciplines including human resources, marketing, medicine, education, political science, criminology, and others.</p>
<p>Logistic regression is one technique that is frequently used to create predictive models where the target is binary. (There are other techniques which will be discussed in subsequent chapters.) To build such a model, a data set is obtained with the following structure shown in Figure <a href="logistic-regression.html#fig:structure">8.1</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:structure"></span>
<img src="images_logistic/DataStructureLogistic.png" alt="Typical data structure." width="60%" />
<p class="caption">
Figure 8.1: Typical data structure.
</p>
</div>
<p>The blue squares in Figure <a href="logistic-regression.html#fig:structure">8.1</a> represent a zero and the maroon squares represent a one. The cases may be individuals, companies, or other types of entities. The predictors can be continuous variables (e.g., age) or categorical (e.g., sex). At first it might seem that a data set with this structure could be analyzed with ordinary least squares regression. There are several reasons why linear is not appropriate, including the fact that the estimates of the target are not constrained to be between 0 and 1. Furthermore, logistic regression does not require the assumption of a normally distributed error term nor the assumption that the error variance is constant. (In fact, the error variance is a function of the predictors.)</p>
<p>One way of understanding the logistic regression model is to think of an intermediate variable (which is not explicitly observed) and the predictors. While the target variable y<sub>i</sub> (where the subscript represents the i<sup>th</sup> case in the data set) is binary, the intermediate variable p<sub>i</sub> is continuous and can be thought of as a propensity for the target to be 1.0 versus 0. Therefore, p<sub>i</sub> is continuous in the range of zero to one. Once p<sub>i</sub> is modeled, then predictions of the target can be obtained by using a decision rule based on a threshold value: if p<sub>i</sub> is greater than the threshold, then y<sub>i</sub> is predicted to be 1; otherwise y<sub>i</sub> is predicted to be 0.</p>
<p>An equation that is a weighted linear combination of the predictors is created. The linear combination can produce a continuous outcome with estimates ranging from -infinity to +infinity. A logit transformation of p<sub>i</sub> to <span class="math inline">\(\hat{y_i}\)</span> is created that results in a continuous variable as a linear function of the predictors:</p>
<p><span class="math display">\[\begin{equation}
    \ \mathit{If}\;p_{i}\; &gt;\; threshold,\;  \hat{y}_{i} = 1;\; else\;  \hat{y}_{i} = 0, \  \mathit{where}\;p_{i}\; = \frac{1}{1 + e^{-(log(odds\;ratio)}}
\end{equation}\]</span></p>
<p>The log odds is a transformation of the probabilities of 1 and 0. In logistic regression the model is estimated as a linear function of log [p(1)/p(0)] where p( ) indicates probability.</p>
<p>The p(1) and p(0) are unobserved; the coefficients of the logistic regression model are estimated using a technique that works to create p(1) and p(0) that maximizes conformance with the observed 1’s and 0’s for the observations in the data set. Unlike ordinary least-squares regression, there is no closed-form algebraic solution to this estimation problem, so an iterative maximum likelihood algorithm can be used.</p>
<p>The effect of the logistic transformation is illustrated in Figure <a href="logistic-regression.html#fig:logisticcurve">8.2</a>. While the variable on the x-axis is continuous, the y-axis variable is constrained to be between zero and one due to the logistic transformation.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:logisticcurve"></span>
<img src="images_logistic/Logisticcurve.png" alt="The logistic function." width="75%" style="background-color: black; padding:2px; display: inline-block;" />
<p class="caption">
Figure 8.2: The logistic function.
</p>
</div>
<p>Note that logistic regression is not the only technique that can be used in these cases. There is a very closely related technique called probit analysis which works in a very similar manner. Instead of using a logistic function for the S-shaped curve, probit analysis uses a cumulative normal function. Investigations of the two techniques have shown very similar results. Also, the hyperbolic tangent function can be used which has properties similar to the logistic function except that it ranges between -1 and +1 instead of 0 and +1. Of course, techniques such as neural networks, decision trees, or discriminant analysis can also be used for with binary targets.</p>
<div id="example-with-a-single-predictor" class="section level2" number="8.1">
<h2><span class="header-section-number">8.1</span> Example with a single predictor</h2>
<p>Consider a very simple classification problem using synthetic data. The example involves predicting purchase (“Yes” or “No”) by a customer as a function of customer’s age. Twenty observations with nine “Yes” values and 11 “No” values were created for demonstration<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a>. A listing of the first 10 rows of the data set is shown in Table <a href="logistic-regression.html#tab:data1">8.1</a>.</p>
<table class=" lightable-paper" style="font-family: &quot;Arial Narrow&quot;, arial, helvetica, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:data1">Table 8.1: </span>First 10 rows of simulated data
</caption>
<thead>
<tr>
<th style="text-align:center;">
Purchase
</th>
<th style="text-align:center;">
Age
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-left:1px solid;border-right:1px solid;">
No
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;">
53
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-left:1px solid;border-right:1px solid;">
No
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;">
51
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-left:1px solid;border-right:1px solid;">
Yes
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;">
43
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-left:1px solid;border-right:1px solid;">
Yes
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;">
36
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-left:1px solid;border-right:1px solid;">
Yes
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;">
33
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-left:1px solid;border-right:1px solid;">
Yes
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;">
30
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-left:1px solid;border-right:1px solid;">
Yes
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;">
41
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-left:1px solid;border-right:1px solid;">
No
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;">
54
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-left:1px solid;border-right:1px solid;">
Yes
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;">
39
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-left:1px solid;border-right:1px solid;">
Yes
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;">
23
</td>
</tr>
</tbody>
</table>
<p>A logistic regression was run with Purchase as the target and Age as the predictor variable. The equation estimated using logistic regression on the data from Table <a href="logistic-regression.html#tab:data1">8.1</a> is:</p>
<p><span class="math display" id="eq:results">\[\begin{equation}
   log \left[  \frac{\;p_{i}\;}{1-\;p_{i}\;} \right] = 11.75 - 0.286 \cdot \;Age_{i}\;
\tag{8.1}    
\end{equation}\]</span></p>
<p>Interpreting the coefficients produced in the logistic regression model is not straightforward due to the non-linear relationship between predictors and probabilities. For this example, it can be noted that since the coefficient on Age is negative, increases in Age result in decreased likelihood of purchasing the product. The value of this coefficient (-0.286) means that a one unit increase in Age is associated with a -0.286 decrease in the log odds of purchase. The intercept (11.75) is usually not of much interest in such problems. The intercept is there to adjust the model to fit the overall proportion of “yeses” and “noes.”</p>
<p>Using equation <a href="logistic-regression.html#eq:prob1">(8.2)</a>, a graph of probability versus age (Figure <a href="logistic-regression.html#fig:probvsage">8.3</a>) was created, showing a decrease in probability as age increases.</p>
<p><span class="math display" id="eq:prob1">\[\begin{equation}
    \;p_{i}\; = \frac{1}{1 + e^{11.75 - 0.286 \cdot \;Age_{i}\;}}
\tag{8.2}   
\end{equation}\]</span></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:probvsage"></span>
<img src="images_logistic/probvsage.png" alt="Probability of purchase versus age." width="75%" style="   border: 1px solid maroon;" />
<p class="caption">
Figure 8.3: Probability of purchase versus age.
</p>
</div>
<p>Equation [3] can also be used to create predictions by comparing each probability to the threshold value using the following decision rules:</p>
<div class="line-block">      If probability of purchase &gt; .5,<br />
      then Most likely purchase=“Yes,”<br />
      else Most likely purchase=No. </div>
<p>Table <a href="logistic-regression.html#tab:data2">8.2</a> shows the results of from applying the decision rule.</p>
<table class=" lightable-paper" style="font-family: &quot;Arial Narrow&quot;, arial, helvetica, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;border-bottom: 0;">
<caption>
<span id="tab:data2">Table 8.2: </span>Predictions using the logistic model.
</caption>
<thead>
<tr>
<th style="text-align:center;">
Purchase
</th>
<th style="text-align:center;">
Age
</th>
<th style="text-align:center;">
Logit
</th>
<th style="text-align:center;">
Probability.of.purchase
</th>
<th style="text-align:center;">
Most.Likely.Purchase
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
No
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
53
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: topwidth: 10em; border-right:1px solid;vertical-align: top">
-3.415
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.032
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
No
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
No
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
51
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: topwidth: 10em; border-right:1px solid;vertical-align: top">
-2.843
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.055
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
No
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
Yes
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
43
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: topwidth: 10em; border-right:1px solid;vertical-align: top">
-0.555
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.366
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
No*
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
Yes
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
36
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: topwidth: 10em; border-right:1px solid;vertical-align: top">
1.448
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.811
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
Yes
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
Yes
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
33
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: topwidth: 10em; border-right:1px solid;vertical-align: top">
2.306
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.910
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
Yes
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
Yes
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
30
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: topwidth: 10em; border-right:1px solid;vertical-align: top">
3.164
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.960
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
Yes
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
Yes
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
41
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: topwidth: 10em; border-right:1px solid;vertical-align: top">
0.018
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.506
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
Yes
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
No
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
54
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: topwidth: 10em; border-right:1px solid;vertical-align: top">
-3.702
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.024
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
No
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
Yes
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
39
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: topwidth: 10em; border-right:1px solid;vertical-align: top">
0.590
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.645
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
Yes
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
Yes
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
23
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: topwidth: 10em; border-right:1px solid;vertical-align: top">
5.167
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.994
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
Yes
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
No
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
40
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: topwidth: 10em; border-right:1px solid;vertical-align: top">
0.304
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.577
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
Yes*
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
No
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
48
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: topwidth: 10em; border-right:1px solid;vertical-align: top">
-1.985
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.122
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
No
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
No
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
58
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: topwidth: 10em; border-right:1px solid;vertical-align: top">
-4.846
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.008
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
No
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
No
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
52
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: topwidth: 10em; border-right:1px solid;vertical-align: top">
-3.129
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.042
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
No
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
No
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
46
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: topwidth: 10em; border-right:1px solid;vertical-align: top">
-1.413
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.197
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
No
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
No
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
34
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: topwidth: 10em; border-right:1px solid;vertical-align: top">
2.020
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.883
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
Yes*
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
No
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
47
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: topwidth: 10em; border-right:1px solid;vertical-align: top">
-1.699
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.156
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
No
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
No
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
44
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: topwidth: 10em; border-right:1px solid;vertical-align: top">
-0.841
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.303
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
No
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
Yes
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
42
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: topwidth: 10em; border-right:1px solid;vertical-align: top">
-0.269
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.435
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
No*
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
Yes
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
25
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: topwidth: 10em; border-right:1px solid;vertical-align: top">
4.595
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.990
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
Yes
</td>
</tr>
</tbody>
<tfoot>
<tr>
<td style="padding: 0; " colspan="100%">
<span style="font-style: italic;">Note: </span> <sup></sup> * Indicates prediction error.
</td>
</tr>
</tfoot>
</table>
<p>The results showing the performance of predictive classification models are typically displayed as a “classification matrix” (also known as a “confusion matrix”) which is shown in Table <a href="logistic-regression.html#tab:data3">8.3</a>.</p>
<table class=" lightable-paper" style="font-family: &quot;Arial Narrow&quot;, arial, helvetica, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:data3">Table 8.3: </span>Confusion matrix
</caption>
<thead>
<tr>
<th style="empty-cells: hide;" colspan="1">
</th>
<th style="padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #00000020; padding-bottom: 5px; ">
Predicted
</div>
</th>
<th style="empty-cells: hide;" colspan="1">
</th>
</tr>
<tr>
<th style="text-align:center;color: black !important;background-color: white !important;padding: 2px;">
Actual
</th>
<th style="text-align:center;color: black !important;background-color: white !important;padding: 2px;">
No
</th>
<th style="text-align:center;color: black !important;background-color: white !important;padding: 2px;">
Yes
</th>
<th style="text-align:center;color: black !important;background-color: white !important;padding: 2px;">
Totals
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; border-right:1px solid;vertical-align: top">
No
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; border-right:1px solid;vertical-align: top">
9
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; border-right:1px solid;vertical-align: top">
2
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;">
11
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; border-right:1px solid;vertical-align: top">
Yes
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; border-right:1px solid;vertical-align: top">
2
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; border-right:1px solid;vertical-align: top">
7
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;">
9
</td>
</tr>
<tr>
<td style="text-align:center;width: 5em; border-right:1px solid;vertical-align: top">
Totals
</td>
<td style="text-align:center;width: 5em; border-right:1px solid;vertical-align: top">
11
</td>
<td style="text-align:center;width: 5em; border-right:1px solid;vertical-align: top">
9
</td>
<td style="text-align:center;">
20
</td>
</tr>
</tbody>
</table>
</div>
<div id="example-predictive-analytic-in-hr" class="section level2" number="8.2">
<h2><span class="header-section-number">8.2</span> Example: Predictive analytic in HR</h2>
<p>Employee retention is an important objective for HR departments in many organizations. According to a report from the Work Institute <span class="citation">(<a href="#ref-Retention" role="doc-biblioref"><span>“2020 Retention Report”</span> 2020</a>)</span>, more than 27 percent of U.S. employees voluntarily left their jobs in 2020 with a total estimate cost of $630 billion due to factors such as cost of replacement, loss of productivity. This same study reported that more than three-fourths of the turnover was preventable.</p>
<p>Using predictive analytics can enable employers to identify employees at risk of leaving and to take preemptive corrective action. A data set on employee turnover was obtained from Kaggle <span class="citation">(<a href="#ref-hr-analytics" role="doc-biblioref"><span>“Hr—Analytics-Employee-Turnover,”</span> n.d.</a>)</span> . This data set has 14,999 rows and 9 columns:</p>
<ol style="list-style-type: decimal">
<li>Satisfaction: Level scored 0 to 1.</li>
<li>Evaluation: Last evaluation rating scored 0 to 1.</li>
<li>Projects: Number of projects completed while at work.</li>
<li>Hours: Average monthly hours at workplace.</li>
<li>Years: Number of years spent in the company.</li>
<li>Promotion: Whether the employee was promoted in the last five years.</li>
<li>Department: Department in which the employee worked.</li>
<li>Salary: Relative level of salary: low, medium, high.</li>
<li>Left: Whether the employee left the workplace or not.</li>
</ol>
<p>A KNIME workflow, shown in Figure <a href="logistic-regression.html#fig:turnoverworkflow">8.4</a>, was created to analyze the HR data.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:turnoverworkflow"></span>
<img src="images_logistic/workflowfemployeeturnover.PNG" alt="KNIME workflow for logistic regression on employee turnover data." width="100%" style="background-color: black; padding:2px; display: inline-block;" />
<p class="caption">
Figure 8.4: KNIME workflow for logistic regression on employee turnover data.
</p>
</div>
<p>A description of each node is shown Table <a href="logistic-regression.html#tab:nodelist">8.4</a>.</p>
<table class=" lightable-paper" style="font-family: &quot;Arial Narrow&quot;, arial, helvetica, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:nodelist">Table 8.4: </span>Description of workflow nodes for employee turnover logistic model.
</caption>
<thead>
<tr>
<th style="text-align:center;">
Node
</th>
<th style="text-align:left;">
Label
</th>
<th style="text-align:left;">
Description
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 2em; vertical-align: top">
1
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
File Reader
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 35em; vertical-align: top">
Read Employee_turnover.csv
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 2em; vertical-align: top">
2
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
Data Explorer
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 35em; vertical-align: top">
Create summary statistics and histograms for each variable. All variables with the exception of YearsAtCompany are okay for analysis. YearsAtCompany is highly skewed, so logarithmic transformation is indicated.
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 2em; vertical-align: top">
3
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
Math Formula
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 35em; vertical-align: top">
Compute ln(YearsAtCompany)
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 2em; vertical-align: top">
4
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
Normalizer
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 35em; vertical-align: top">
Rescale continuous variables to range of 0 to 1.
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 2em; vertical-align: top">
5
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
Partitioning
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 35em; vertical-align: top">
A 70/30 (Training/Test) random split of the data set stratified on Left is formed. Set random seed = 123. The Test portion is set aside for validation.
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 2em; vertical-align: top">
6
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
SMOTE
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 35em; vertical-align: top">
SMOTE (Synthetic Minority Over-sampling Technique) oversamples the class where employees Left in order to create an equal number of those who Left and those who Did not leave. By balancing the target variable a better logistic model is formed.
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 2em; vertical-align: top">
7
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
X-Partitioner
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 35em; vertical-align: top">
The beginning loop of a 10-fold cross validation is created.
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 2em; vertical-align: top">
8
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
Logistic Regression Learner
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 35em; vertical-align: top">
Run logistic regression with Left as the target.
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 2em; vertical-align: top">
9
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
Logistic Regression Predictor
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 35em; vertical-align: top">
Predict the response from the logistic regression model using the Training data.
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 2em; vertical-align: top">
10
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
X-Aggregator
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 35em; vertical-align: top">
The end of the cross validation loop.
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 2em; vertical-align: top">
11
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
ROC Curve
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 35em; vertical-align: top">
Create ROC curve for the Training data.
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 2em; vertical-align: top">
12
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
Scorer
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 35em; vertical-align: top">
Compute performance statistics and classification (confusion) matrix for the Training data.
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 2em; vertical-align: top">
13
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
Logistic Regression Predictor
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 35em; vertical-align: top">
Predict the response from the logistic regression model using the Test data.
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 2em; vertical-align: top">
14
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
ROC Curve
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 35em; vertical-align: top">
Create ROC curve for the Test data.
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 2em; vertical-align: top">
15
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
Scorer
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 35em; vertical-align: top">
Compute performance statistics and classification (confusion) matrix for the Test data.
</td>
</tr>
</tbody>
</table>
<p>In Node 1 the data set with 14,999 observations and nine variables was read using the File Reader node. Promotion, Salary and Left are string variables; the others are numeric. The data set was explored using Data Explorer. All of the variables appeared to be suitable for analysis with the exception of YearsAtCompany which was highly skewed as shown in the histogram below in Figure <a href="logistic-regression.html#fig:historgramyears">8.5</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:historgramyears"></span>
<img src="images_logistic/HistogramYearsAtCompany.PNG" alt="Histogram of YearsAtCompany." width="50%" style="background-color: black; padding:2px; display: inline-block;" />
<p class="caption">
Figure 8.5: Histogram of YearsAtCompany.
</p>
</div>
<p>Since a skewed variable can lead to poorer performance with logistic regression, a transformation of YearsAtCompany was computed using a Math Formula (Node 3) and the original variable replaced in the subsequent nodes. This reduced the skewness of YearsAtCompany from 1.85 to 0.59.</p>
<p>Predictive models typically do better with normalized predictors, so the following variables were normalized (Node 4) to a range of 0 to 1: Satisfaction, Evaluation, Projects, Hours, and Years.</p>
<p>In Node 5 the data was split randomly into two subsets: Training and Test. The split ratio was 70/30 and the sample was stratified on Left so that the proportions of Left / Did not leave would be about the same in both the Training and Test partitions.</p>
<p>SMOTE (Node 6) was used to oversample the Left category. Prior to oversampling, the split in the Training partition was 7,999 Left and 2,499 Did not leave. Such an imbalance in a binary target variable will usually cause the logistic regression to make most predictions to the level with the larger number of cases. After applying SMOTE, both levels (Left and Did not leaver) had 7,999 cases. This balanced sample was used to build the logistic model, but the evaluation of the model performance was done using the Test set with the original level proportions. The balanced sample was used to facilitate the estimation of the logistic regression model <span class="citation">(<a href="#ref-Sala-Eljatiba" role="doc-biblioref">ChristianSalas-Eljatiba and ValeskaYaitul 2018</a>)</span>.</p>
<p>A k-fold cross validation (Node 7) was used to assess the stability of the logistic model using the Training data by employing the X-Partitioner and X-Aggregator nodes in KNIME with k = 10. The Training data is divided randomly into 10 approximately equal segments. Then, the logistic regression was run 10 times, each time withholding a 10% subset. Logistic regression requires two steps in KNIME; in Node 8 the Logistic Regression Learner runs the model and outputs the model coefficients; in Node 9 the Logistic Regression Predictor is applied to compute predictions for each row of the Training data. The 10 held out samples were used to assess the predictive accuracy. The results of the 10 runs were obtained from the output of Node 10 and are shown in Table <a href="logistic-regression.html#tab:kfold">8.5</a>.</p>
<table class=" lightable-paper" style="font-family: &quot;Arial Narrow&quot;, arial, helvetica, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:kfold">Table 8.5: </span>Results of k-fold validation.
</caption>
<thead>
<tr>
<th style="text-align:center;">
Fold
</th>
<th style="text-align:center;">
Error in %
</th>
<th style="text-align:center;">
Accuracy in %
</th>
<th style="text-align:center;">
Size of test set
</th>
<th style="text-align:center;">
Error count
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; border-right:1px solid;vertical-align: top">
fold 0
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
18.6
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
81.4
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
1600
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
354
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; border-right:1px solid;vertical-align: top">
fold 1
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
19.0
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
81.0
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
1600
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
323
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; border-right:1px solid;vertical-align: top">
fold 2
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
19.7
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
80.3
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
1600
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
358
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; border-right:1px solid;vertical-align: top">
fold 3
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
18.4
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
81.6
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
1600
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
379
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; border-right:1px solid;vertical-align: top">
fold 4
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
19.9
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
80.1
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
1600
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
341
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; border-right:1px solid;vertical-align: top">
fold 5
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
20.7
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
79.3
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
1600
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
323
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; border-right:1px solid;vertical-align: top">
fold 6
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
19.0
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
81.0
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
1600
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
354
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; border-right:1px solid;vertical-align: top">
fold 7
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
18.7
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
81.3
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
1600
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
349
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; border-right:1px solid;vertical-align: top">
fold 8
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
20.3
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
79.7
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
1599
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
331
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; border-right:1px solid;vertical-align: top">
fold 9
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
21.1
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
78.9
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
1599
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
335
</td>
</tr>
</tbody>
</table>
<p>The average accuracy was 80.57%, with a maximum of 81.63% and a minimum of 78.86%. This shows that the model had reasonable accuracy and was quite stable in performance across the 10 folds. Recall that these analyses were conducted using the oversampled data.</p>
<p>The final model from Node 10 (using the last of the 10-fold partitions) was passed to the evaluation nodes for the Training data. The predictions for the Training data computed in Node 10. An ROC curve was created in Node 11 and the Scorer Node 12 created a classification (or confusion) matrix along with several evaluation metrics. A corresponding set of analyses was run for the Test data, shown in Nodes 13, 14, and 15.</p>
<p>The classification matrices for the Training and Test data are shown in the Tables <a href="logistic-regression.html#tab:data4">8.6</a> and <a href="logistic-regression.html#tab:data5">8.7</a>.</p>
<table class=" lightable-paper" style="font-family: &quot;Arial Narrow&quot;, arial, helvetica, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:data4">Table 8.6: </span>Confusion matrix for training data.
</caption>
<thead>
<tr>
<th style="empty-cells: hide;" colspan="1">
</th>
<th style="padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #00000020; padding-bottom: 5px; ">
Predicted
</div>
</th>
<th style="empty-cells: hide;" colspan="1">
</th>
</tr>
<tr>
<th style="text-align:center;color: black !important;background-color: white !important;padding: 2px;">
Actual
</th>
<th style="text-align:center;color: black !important;background-color: white !important;padding: 2px;">
Left company
</th>
<th style="text-align:center;color: black !important;background-color: white !important;padding: 2px;">
Did not leave
</th>
<th style="text-align:center;color: black !important;background-color: white !important;padding: 2px;">
Total
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
Left company
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
6,909
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
1,090
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
7,999
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
Did not leave
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
2,035
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
5,964
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
7,989
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
Total
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
8,944
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
7,054
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
15,900
</td>
</tr>
</tbody>
</table>
<table class=" lightable-paper" style="font-family: &quot;Arial Narrow&quot;, arial, helvetica, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:data5">Table 8.7: </span>Confusion matrix for test data.
</caption>
<thead>
<tr>
<th style="empty-cells: hide;" colspan="1">
</th>
<th style="padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #00000020; padding-bottom: 5px; ">
Predicted
</div>
</th>
<th style="empty-cells: hide;" colspan="1">
</th>
</tr>
<tr>
<th style="text-align:center;color: black !important;background-color: white !important;padding: 2px;">
Actual
</th>
<th style="text-align:center;color: black !important;background-color: white !important;padding: 2px;">
Left company
</th>
<th style="text-align:center;color: black !important;background-color: white !important;padding: 2px;">
Did not leave
</th>
<th style="text-align:center;color: black !important;background-color: white !important;padding: 2px;">
Total
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
Left company
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
919
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
152
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
1,071
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
Did not leave
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
879
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
2,559
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
3,429
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
Total
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
1,789
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
2,711
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
4,500
</td>
</tr>
</tbody>
</table>
<p>Note that the results for the Training data are based on the oversampled data while the Test data results used the original ratio of Left versus Did not leave. The imbalanced data created less than ideal results. The Scorer Nodes (13 and 15) also provide summary descriptive statistics derived from the classification matrices. The results for both partitions are shown in Table <a href="logistic-regression.html#tab:data6">8.8</a>.</p>
<table class=" lightable-paper" style="font-family: &quot;Arial Narrow&quot;, arial, helvetica, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:data6">Table 8.8: </span>Performance metrics for training and test data.
</caption>
<thead>
<tr>
<th style="text-align:left;">
Metric
</th>
<th style="text-align:center;">
Training data
</th>
<th style="text-align:center;">
Test data
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
Accuracy
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 8em; border-right:1px solid;vertical-align: top">
0.805
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 8em; border-right:1px solid;vertical-align: top">
0.773
</td>
</tr>
<tr>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
Cohen’s kappa
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 8em; border-right:1px solid;vertical-align: top">
0.609
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 8em; border-right:1px solid;vertical-align: top">
0.491
</td>
</tr>
<tr>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
Precision
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 8em; border-right:1px solid;vertical-align: top">
0.772
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 8em; border-right:1px solid;vertical-align: top">
0.514
</td>
</tr>
<tr>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
Sensitivity
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 8em; border-right:1px solid;vertical-align: top">
0.864
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 8em; border-right:1px solid;vertical-align: top">
0.858
</td>
</tr>
<tr>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
Specificity
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 8em; border-right:1px solid;vertical-align: top">
0.746
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 8em; border-right:1px solid;vertical-align: top">
0.749
</td>
</tr>
<tr>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
F-measure
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 8em; border-right:1px solid;vertical-align: top">
0.834
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 8em; border-right:1px solid;vertical-align: top">
0.643
</td>
</tr>
</tbody>
</table>
<p>The overall accuracies for the Training and Test data sets were close, with a slight edge for the Training data. This is to be expected since the logistic regression was optimized for the Training data. However, accuracy is not the best measure in this situation due to the imbalance in the binary outcomes. In fact, if all observations in the Test data a predicted Did not leave, the accuracy would be .762. This approach would not be useful, of course, since it never identifies any of those that left the company.</p>
<p>Cohen’s kappa was lower in the Test data than with the Training data. This is likely due to the imbalance in binary outcomes in the original data. It is known that Kappa reaches its maximum of 1.0 only for balanced outcomes, so the lower kappa in the Test data is not surprising <span class="citation">(<a href="#ref-CohenKappa" role="doc-biblioref">Widmann, n.d.</a>)</span>.</p>
<p>An area of concern with the results for the Test data is precision, which is much lower for the Test data than for the Training data. This too is due to the imbalance in the number of cases which Left versus the number that Did not leave. Because of this imbalance, it is “easier” to predict Did not leave. In the context of this HR application, it could be argued that mistakenly predicting an employee will leave is not as serious as failing to predict that an employee would leave. The sensitivity for predicting who is likely to lead was more than 0.8 with the training data. Thus, the vast majority of those likely to turnover can be identified. In such a situation the results of the model can only be used to signal HR that a further investigation of those identified as likely to leave.</p>
<p>ROC curves were obtained for the Training data in Node 12 and the testing data in Node 15. The curves are shown in Figures <a href="logistic-regression.html#fig:rocTraining">8.6</a> and <a href="logistic-regression.html#fig:rocTest">8.7</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:rocTraining"></span>
<img src="images_logistic/ROC1.PNG" alt="ROC curve for the training data. (AUC = 0.829)" width="75%" style="background-color: black; padding:2px; display: inline-block;" />
<p class="caption">
Figure 8.6: ROC curve for the training data. (AUC = 0.829)
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:rocTest"></span>
<img src="images_logistic/ROC2.PNG" alt="ROC curve for the training data. (AUC = 0.833)" width="75%" style="background-color: black; padding:2px; display: inline-block;" />
<p class="caption">
Figure 8.7: ROC curve for the training data. (AUC = 0.833)
</p>
</div>
<p>The ROC curves for both data sets are quite similar, indicating comparable predictive performance with the Training and Test data. The areas under the ROC curves (AUC) for both are about 0.83, which is fairly high, as the AUC varies from 0.0 to 1.0.
The overall assessment of the logistic model with this data is that it would be useful in identifying employees likely to turnover when the predictor variables are input to the model. As noted earlier, however, when an employee is predicted to turnover, additional human review is needed since the precision of the model was not high.</p>
</div>
<div id="predictor-interpretation-and-importance" class="section level2" number="8.3">
<h2><span class="header-section-number">8.3</span> Predictor interpretation and importance</h2>
<p>Some questions about this predictive model are: “How can the changes in the predictor variables be interpreted? What is the relative importance of each of the predictors of employee turnover?” Answering this might provide insight into what steps might be taken to reduce turnover.</p>
<p>The question of predictor (or feature) importance has been studied extensively with multiple regression models. However, comparatively little has been published about measuring predictive importance in logistic regression <span class="citation">(<a href="#ref-Azen" role="doc-biblioref">Azen and Traxel 2009</a>)</span>. An approach based on “dominance analysis” has been developed and is available in Python and R. Dominance analysis is not directly available in KNIME. A simpler approach will be discussed in this section (but one that has limitations like any of the other methods).</p>
<p>The coefficients on the predictors cannot be used to infer importance in logistic regression because these coefficients are for the log of the odds. Rather, what is usually desired is the impact on the probability of changes in each predictor. This is further complicated because the effect on probability of the outcome is not linear, and the probabilities associated with a predictor depend upon the values for the other predictors. Thus, the “importance” of a particular predictor varies based on the range of the predictor being considered and the settings of every other predictor. So, the relative sizes of the coefficients in a logistic model cannot indicate predictor importance, even if the predictor variables are normalized.</p>
<p>Likewise, the p-values for significance tests on each predictor cannot be interpreted as a measure of importance in a practical sense. A small p-value indicates that the variable has a low variance compared with its magnitude, but the variable could still have a very minor effect on the target variable.</p>
<p>In general, for binary logistic models no approach to interpretation can fully describe the relationship between changes in a predictor value and the probability of the target variable <span class="citation">(<a href="#ref-Long2006" role="doc-biblioref">Long and Frees 2006</a>)</span>.<br />
An approach is to examine the effect on the probability of the outcome as each predictor is varied from its minimum to maximum. Since the results of changing one input variable depend upon the values of the other predictors, a “baseline” set of values for the predictors was established. Each of the continuous predictors was set to their respective means and the nominal values were set to the modal values. The results (Table <a href="logistic-regression.html#tab:data7">8.9</a>) indicate that “Number of years spend in the company” was most important followed by Satisfaction. Note that this still does not fully address the question of interpretation, but it may provide some insight.</p>
<table class=" lightable-paper" style="font-family: &quot;Arial Narrow&quot;, arial, helvetica, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:data7">Table 8.9: </span>Range of probabilities of leaving by predictors.
</caption>
<thead>
<tr>
<th style="text-align:left;">
Predictor
</th>
<th style="text-align:center;">
Range
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
Last evaluation rating scored
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
0.12
</td>
</tr>
<tr>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
Department in which the employee worked
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
0.23
</td>
</tr>
<tr>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
Average monthly hours at workplace
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
0.33
</td>
</tr>
<tr>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
Whether the employee promoted in last five years
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
0.39
</td>
</tr>
<tr>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
Relative level of salary: low
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
0.47
</td>
</tr>
<tr>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
Number of projects completed while at work
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
0.51
</td>
</tr>
<tr>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
Satisfaction
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
0.75
</td>
</tr>
<tr>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
Number of years spent in the company
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
0.77
</td>
</tr>
</tbody>
</table>
<p>Another approach to interpreting predictors is to chart changes in probability by a predictor at different levels of another predictor. Figure <a href="logistic-regression.html#fig:levels">8.8</a> shows how the probability of leaving the company varies with level of satisfaction at three salary levels. As might be expected, employees with Low salary were generally more likely to leave at any level of satisfaction.</p>
<p>This type of analysis is useful when examining the impact of two variables but still does not fully address the question of variable importance.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:levels"></span>
<img src="images_logistic/levels.PNG" alt="Probability of leaving by satisfaction for different salary levels." width="50%" style="background-color: black; padding:2px; display: inline-block;" />
<p class="caption">
Figure 8.8: Probability of leaving by satisfaction for different salary levels.
</p>
</div>
</div>
<div id="regularized-logistic-regression" class="section level2" number="8.4">
<h2><span class="header-section-number">8.4</span> Regularized logistic regression</h2>
<p>Next, we will look at a subset of the data used in a Kaggle competition developed by the University of Melbourne which asked participants to predict the success of research grant applications. The subset used is based on the involved data preparation process available in the R package “Applied Predictive Modeling” . A subset of the data in that package was created by removing observations with missing values, yielding a total of 5,503 observations on 258 columns, including the binary target column “Class” (successful versus unsuccessful).</p>
<p>As discussed in the chapter on regression, KNIME includes an integration of algorithms from the H2O suite of analytics programs. The H2O algorithm “Generalized Linear Model (GLM)” was used to analyze the grant application data. The GLM program was run with the following settings:</p>
<ul>
<li>Target Column =&gt; Class</li>
<li>Predictors =&gt; NumCI through Day (257 columns)</li>
<li>The Ignore constant columns was checked</li>
<li>The random seed was set to 123.</li>
<li>The algorithm family was set to Binomial, the Link to logit.</li>
<li>The alpha parameter controls the penalty functions for LASSO and ridge regression. An alpha of 1.0 produces LASSO and 0.0 produces ridge regression. This was set to 1.0 for LASSO.</li>
</ul>
<p>The lambda parameter controls the amount of regularization from 0 (no regularization) and to larger values for more regularization. The option to perform an automatic search for the optimal value of the lambda parameter was selected. GLM will first fit a model with maximum regularization using a high lambda value that causes all coefficients to be zero, and then sequentially reduces lambda until the minimum lambda (set to .0001) or until overfitting occurs. The best value for lambda is determined by using the validation subset of the data, which was set to 15%. The best lambda is that which maximizes the log-likelihood in the GLM model).</p>
<p>A workflow for the regularized logistic regression was created using KNIME and H2O (Figure <a href="logistic-regression.html#fig:H2O">8.9</a>) with corresponding node descriptions in Table <a href="logistic-regression.html#tab:data8">8.10</a>. Note that the optimum value of lambda is found independently of the test data.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:H2O"></span>
<img src="images_logistic/H2Oworkflow.PNG" alt="Probability of leaving by satisfaction for different salary levels." width="75%" style="background-color: black; padding:2px; display: inline-block;" />
<p class="caption">
Figure 8.9: Probability of leaving by satisfaction for different salary levels.
</p>
</div>
<table class=" lightable-paper" style="font-family: &quot;Arial Narrow&quot;, arial, helvetica, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:data8">Table 8.10: </span>Node descriptions for regularized logistic regression.
</caption>
<thead>
<tr>
<th style="text-align:center;">
Node
</th>
<th style="text-align:left;">
Label
</th>
<th style="text-align:left;">
Description
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
1
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
File Reader
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
Read grantdata1.csv.
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
2
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
H2O Local Connect
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
Allows running H2O models in KNIME workflow.
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
3
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
Table to H2O
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
Convert KNIME data to H2O frame.
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
4
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
H2O Partitioning
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
An 80/20 (Training/Test) random split of the data set stratified on Class, random seed = 123. The Test portion is set aside for validation.
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
5
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
H2O Generalized Linear Model Learner
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
GLM set up to run logistic regression with regulation.
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
6
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
H2O Predictor (Classification)
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
Create predictions and probabilities.
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
7
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
H2O to Table
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 25em; vertical-align: top">
Convert H2O frame to KNIME data.
</td>
</tr>
</tbody>
</table>
<p>Regularization was able to simplify the model considerably (with 74 fewer predictors) and actually improved the area under the ROC curve, accuracy, and sensitivity (Table <a href="logistic-regression.html#tab:data9">8.11</a>). Specificity was slightly lower with the regularized model.</p>
<table class=" lightable-paper" style="font-family: &quot;Arial Narrow&quot;, arial, helvetica, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:data9">Table 8.11: </span>Comparison of full and regularized logistic regression models.
</caption>
<thead>
<tr>
<th style="empty-cells: hide;" colspan="1">
</th>
<th style="padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #00000020; padding-bottom: 5px; ">
Model and number of predictors
</div>
</th>
</tr>
<tr>
<th style="text-align:left;color: black !important;background-color: white !important;padding: 2px;">
Metric
</th>
<th style="text-align:center;color: black !important;background-color: white !important;padding: 2px;">
Full (257)
</th>
<th style="text-align:center;color: black !important;background-color: white !important;padding: 2px;">
Regularized (184)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
AUC
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.897
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.903
</td>
</tr>
<tr>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
Accuracy
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.823
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.828
</td>
</tr>
<tr>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
Sensitivity
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.814
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.833
</td>
</tr>
<tr>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 5em; vertical-align: top">
Specificity
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.831
</td>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 10em; vertical-align: top">
0.824
</td>
</tr>
</tbody>
</table>
</div>
<div id="probability-calibration" class="section level2" number="8.5">
<h2><span class="header-section-number">8.5</span> Probability calibration</h2>
<p>In some applications, it is important to predict the probability that an observation belongs to a specific classification outcome. Performance metrics such as accuracy, sensitivity, and specificity focus on the overall classification to one of two outcomes. Typical models are also used to provide a rank ordering of cases from highest to lowest probability. Such metrics may not correspond to the actual frequencies of outcomes. In other words, the probabilities are not calibrated to the “true” probabilities. Some algorithms, such as support vector machines, boosted trees, and naïve Bayes may be accurate in terms of classification, but not in terms of matching probabilities. Logistic regression has been shown to produce well-calibrated probabilities. In this section we will assess the calibration of logistic regression and present two calibration methods, Platt Scaling and Isotonic Regression.</p>
<p>Assessing calibration accuracy with binary outcomes can be done via a calibration plot of the observed fraction of positive outcomes versus the mean probability obtained from a model. A calibration plot for the success of grant applications example from the previous section was computed. Nodes were added to the workflow shown in Figure <a href="logistic-regression.html#fig:H2O">8.9</a>). The output of the H2O to Table node from that workflow was submitted to the following series of nodes (Figure <a href="logistic-regression.html#fig:workflow5">8.10</a> and Table <a href="logistic-regression.html#tab:calibration">8.12</a>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:workflow5"></span>
<img src="images_logistic/calibration.PNG" alt="Workflow for creating calibration plot." width="100%" style="background-color: black; padding:2px; display: inline-block;" />
<p class="caption">
Figure 8.10: Workflow for creating calibration plot.
</p>
</div>
<table class=" lightable-paper" style="font-family: &quot;Arial Narrow&quot;, arial, helvetica, sans-serif; width: auto !important; margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:calibration">Table 8.12: </span>Node descriptions for calibration workflow.
</caption>
<thead>
<tr>
<th style="text-align:center;">
Node
</th>
<th style="text-align:left;">
Label
</th>
<th style="text-align:left;">
Description
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 2em; border-right:1px solid;vertical-align: top">
10
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
Column Filter
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 35em; vertical-align: top">
Select columns needed for calibration: ROWNUM, actual class, predicted probability of success.
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 2em; border-right:1px solid;vertical-align: top">
11
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
Numeric Binner
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 35em; vertical-align: top">
Create bins of probabilities from 0 to 1 in increments of .1.
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 2em; border-right:1px solid;vertical-align: top">
12
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
Pivoting
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 35em; vertical-align: top">
Create pivot table of bins, count of successful and unsuccessful
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 2em; border-right:1px solid;vertical-align: top">
13
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
Column Expressions
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 35em; vertical-align: top">
Calculate fraction of success
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 2em; border-right:1px solid;vertical-align: top">
14
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
GroupBy
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 35em; vertical-align: top">
Calculate mean probability by bin
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 2em; border-right:1px solid;vertical-align: top">
15
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
Joiner
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 35em; vertical-align: top">
Join fraction of success and mean probability
</td>
</tr>
<tr>
<td style="text-align:center;color: black !important;background-color: white !important;padding: 2px;width: 2em; border-right:1px solid;vertical-align: top">
16
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 10em; border-right:1px solid;vertical-align: top">
Excel Writer
</td>
<td style="text-align:left;color: black !important;background-color: white !important;padding: 2px;width: 35em; vertical-align: top">
Output results to Excel for charting
</td>
</tr>
</tbody>
</table>
<p>The logistic regression was fairly well calibrated, with some deviation in the mid-range of probabilities (Figure <a href="logistic-regression.html#fig:calibrationCurve">8.11</a>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:calibrationCurve"></span>
<img src="images_logistic/calibrationCurve.PNG" alt="Calibration of logistic regression probabilities." width="50%" style="background-color: black; padding:2px; display: inline-block;" />
<p class="caption">
Figure 8.11: Calibration of logistic regression probabilities.
</p>
</div>
</div>
<div id="evaluation-of-logistic-regression" class="section level2" number="8.6">
<h2><span class="header-section-number">8.6</span> Evaluation of logistic regression</h2>
<p>Logistic regression is one of the most used algorithms for predicting binary classes. It is easy to run and can handle large numbers of observations efficiently. As with ordinary regression, the number of observations in an analysis should be much greater than the number of predictors. Also, care should be taken to avoid overfitting (as is true of most supervised models). While logistic regression can be used to predict categorical targets with three or more levels, other models such as decision trees, neural nets, k nearest neighbors are better choices for such problems. In some cases, multi-class problems can be converted to just two levels so logistic regression can be meaningfully applied.</p>
<p>The H2O GLM regularization model available in KNIME was demonstrated with a fairly large data set. Regularization reduced the number of predictors significantly while maintaining overall model performance. The estimated probabilities from the model were generally aligned with the observed proportions.</p>
<p>Logistic regression assumes linearity between the log-odds ratio and the predictor variables. Interactions can be created, but this can cause computational problems. As discussed earlier, interpreting the coefficients on predictors is not straightforward since each coefficient reflects the change in log odds which is difficult to intuit.</p>
<p>Finally, with some data samples logistic regression can result in failure to converge to a solution. One other issue is the potential for complete separation of the data by a single feature. In this situation, no weight can be estimated for the feature in question; it is essentially infinite.</p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Retention" class="csl-entry">
<span>“2020 Retention Report.”</span> 2020. Work Institute. https://doi.org/<a href="https://doi.org/&quot; &quot; ">" "</a>.
</div>
<div id="ref-Azen" class="csl-entry">
Azen, Razia, and Nicole Traxel. 2009. <span>“Using Dominance Analysis to Determine Predictor Importance in Logistic Regression.”</span> <em>Journal of Educational and Behavioral Statistics</em> 34: 319–47.
</div>
<div id="ref-Sala-Eljatiba" class="csl-entry">
ChristianSalas-Eljatiba, Timothy G. Gregoireb, AndresFuentes-Ramireza, and ValeskaYaitul. 2018. <span>“A Study on the Effects of Unbalanced Data When Fitting Logistic Regression Models in Ecology.”</span> <em>Ecological Indicators</em>, 502–8.
</div>
<div id="ref-hr-analytics" class="csl-entry">
<span>“Hr—Analytics-Employee-Turnover.”</span> n.d. Work Institute. https://doi.org/<a href="https://doi.org/&quot; &quot;   ">" "</a>.
</div>
<div id="ref-Long2006" class="csl-entry">
Long, J. Scott, and Jeremy Frees. 2006. <em>Regression Models for Categorical Dependent Variables Using Stata</em>. 2nd ed. College Station, Texas: Chapman; Hall/CRC.
</div>
<div id="ref-CohenKappa" class="csl-entry">
Widmann, Maarit. n.d. <span>“Cohen’s Kappa: What It Is, When to Use It, and How to Avoid Its Pitfalls.”</span> <a href="https://thenewstack.io/cohens-kappa-what-it-is-when-to-use-it-and-how-to-avoid-its-pitfalls/#:~:text=Cohen&#39;s%20kappa%20is%20a%20metric,performance%20of%20a%20classification%20model.&amp;text=Like%20many%20other%20evaluation%20metrics,based%20on%20the%20confusion%20matrix">https://thenewstack.io/cohens-kappa-what-it-is-when-to-use-it-and-how-to-avoid-its-pitfalls/#:~:text=Cohen's%20kappa%20is%20a%20metric,performance%20of%20a%20classification%20model.&amp;text=Like%20many%20other%20evaluation%20metrics,based%20on%20the%20confusion%20matrix</a>.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="12">
<li id="fn12"><p>This example is for illustration only. Predictive analysis in a data mining context should not be used with such a small data set.<a href="logistic-regression.html#fnref12" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="multiple-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="ensemble-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["TextbookDraft.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
