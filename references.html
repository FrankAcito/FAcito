<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>References | Analytics with KNIME and R</title>
  <meta name="description" content="This is a draft." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="References | Analytics with KNIME and R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a draft." />
  <meta name="github-repo" content="rstudio/bookdown-demo" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="References | Analytics with KNIME and R" />
  
  <meta name="twitter:description" content="This is a draft." />
  

<meta name="author" content="F Acito" />


<meta name="date" content="2021-11-16" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="cluster-analysis.html"/>

<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Cover page</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#what-is-analytics"><i class="fa fa-check"></i><b>1.1</b> What is analytics?</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#some-trends-in-analytics"><i class="fa fa-check"></i><b>1.2</b> Some trends in analytics</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="intro.html"><a href="intro.html#broadening-of-application-areas"><i class="fa fa-check"></i><b>1.2.1</b> Broadening of application areas</a></li>
<li class="chapter" data-level="1.2.2" data-path="intro.html"><a href="intro.html#generalization-of-the-notion-of-data"><i class="fa fa-check"></i><b>1.2.2</b> Generalization of the notion of data</a></li>
<li class="chapter" data-level="1.2.3" data-path="intro.html"><a href="intro.html#a-trend-from-slicing-and-dicing-data-to-more-advanced-techniques"><i class="fa fa-check"></i><b>1.2.3</b> A trend from “slicing and dicing” data to more advanced techniques</a></li>
<li class="chapter" data-level="1.2.4" data-path="intro.html"><a href="intro.html#more-advanced-data-visualization"><i class="fa fa-check"></i><b>1.2.4</b> More advanced data visualization</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#the-analytics-process-model"><i class="fa fa-check"></i><b>1.3</b> The analytics process model</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html"><i class="fa fa-check"></i><b>2</b> Business understanding and problem definition</a>
<ul>
<li class="chapter" data-level="2.1" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html#expert-views"><i class="fa fa-check"></i><b>2.1</b> Expert views</a></li>
<li class="chapter" data-level="2.2" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html#understanding-the-business"><i class="fa fa-check"></i><b>2.2</b> Understanding the business</a></li>
<li class="chapter" data-level="2.3" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html#identifying-stakeholders"><i class="fa fa-check"></i><b>2.3</b> Identifying stakeholders</a></li>
<li class="chapter" data-level="2.4" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html#structured-versus-unstructured-problems"><i class="fa fa-check"></i><b>2.4</b> Structured versus unstructured problems</a></li>
<li class="chapter" data-level="2.5" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html#framing-the-problem"><i class="fa fa-check"></i><b>2.5</b> Framing the problem</a></li>
<li class="chapter" data-level="2.6" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html#summary"><i class="fa fa-check"></i><b>2.6</b> Summary</a></li>
<li class="chapter" data-level="" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html#appendix-some-tools-for-problem-definition"><i class="fa fa-check"></i>Appendix: Some tools for problem definition</a>
<ul>
<li class="chapter" data-level="" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html#right-to-left-thinking"><i class="fa fa-check"></i>Right to left thinking</a></li>
<li class="chapter" data-level="" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html#reversing-the-problem"><i class="fa fa-check"></i>Reversing the problem</a></li>
<li class="chapter" data-level="" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html#open-the-problem-with-whys"><i class="fa fa-check"></i>Open the problem with “whys”</a></li>
<li class="chapter" data-level="" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html#challenge-assumptions"><i class="fa fa-check"></i>Challenge assumptions</a></li>
<li class="chapter" data-level="" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html#chunking"><i class="fa fa-check"></i>Chunking</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="business-understanding-and-problem-definition.html"><a href="business-understanding-and-problem-definition.html#problems"><i class="fa fa-check"></i>Problems</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="introduction-to-knime.html"><a href="introduction-to-knime.html"><i class="fa fa-check"></i><b>3</b> Introduction to KNIME</a>
<ul>
<li class="chapter" data-level="3.1" data-path="introduction-to-knime.html"><a href="introduction-to-knime.html#the-knime-workbench"><i class="fa fa-check"></i><b>3.1</b> The KNIME Workbench</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="introduction-to-knime.html"><a href="introduction-to-knime.html#elements-of-the-knime-workbench"><i class="fa fa-check"></i><b>3.1.1</b> Elements of the KNIME Workbench</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="introduction-to-knime.html"><a href="introduction-to-knime.html#learning-to-use-knime"><i class="fa fa-check"></i><b>3.2</b> Learning to use KNIME</a></li>
<li class="chapter" data-level="3.3" data-path="introduction-to-knime.html"><a href="introduction-to-knime.html#knime-extensions-and-integrations"><i class="fa fa-check"></i><b>3.3</b> KNIME extensions and integrations</a></li>
<li class="chapter" data-level="3.4" data-path="introduction-to-knime.html"><a href="introduction-to-knime.html#knime-workflow-example-1-predicting-heart-disease"><i class="fa fa-check"></i><b>3.4</b> KNIME workflow example #1: Predicting heart disease</a></li>
<li class="chapter" data-level="3.5" data-path="introduction-to-knime.html"><a href="introduction-to-knime.html#knime-workflow-example-2-preparation-of-hospital-data"><i class="fa fa-check"></i><b>3.5</b> KNIME workflow example #2: Preparation of hospital data</a></li>
<li class="chapter" data-level="3.6" data-path="introduction-to-knime.html"><a href="introduction-to-knime.html#summary-1"><i class="fa fa-check"></i><b>3.6</b> Summary</a></li>
<li class="chapter" data-level="" data-path="introduction-to-knime.html"><a href="introduction-to-knime.html#problems-1"><i class="fa fa-check"></i>Problems</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="data-preparation.html"><a href="data-preparation.html"><i class="fa fa-check"></i><b>4</b> Data preparation</a>
<ul>
<li class="chapter" data-level="4.1" data-path="data-preparation.html"><a href="data-preparation.html#introduction"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="data-preparation.html"><a href="data-preparation.html#obtaining-the-needed-data"><i class="fa fa-check"></i><b>4.2</b> Obtaining the needed data</a></li>
<li class="chapter" data-level="4.3" data-path="data-preparation.html"><a href="data-preparation.html#data-cleaning"><i class="fa fa-check"></i><b>4.3</b> Data cleaning</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="data-preparation.html"><a href="data-preparation.html#missing-values"><i class="fa fa-check"></i><b>4.3.1</b> Missing values</a></li>
<li class="chapter" data-level="4.3.2" data-path="data-preparation.html"><a href="data-preparation.html#outliers"><i class="fa fa-check"></i><b>4.3.2</b> Outliers</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="data-preparation.html"><a href="data-preparation.html#feature-engineering"><i class="fa fa-check"></i><b>4.4</b> Feature engineering</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="data-preparation.html"><a href="data-preparation.html#data-transformations"><i class="fa fa-check"></i><b>4.4.1</b> Data transformations</a></li>
<li class="chapter" data-level="4.4.2" data-path="data-preparation.html"><a href="data-preparation.html#data-exploration"><i class="fa fa-check"></i><b>4.4.2</b> Data exploration</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="principal-components-analytics.html"><a href="principal-components-analytics.html"><i class="fa fa-check"></i><b>5</b> Principal components analytics</a>
<ul>
<li class="chapter" data-level="5.1" data-path="principal-components-analytics.html"><a href="principal-components-analytics.html#approaches-to-dimension-reduction"><i class="fa fa-check"></i><b>5.1</b> Approaches to dimension reduction</a></li>
<li class="chapter" data-level="5.2" data-path="principal-components-analytics.html"><a href="principal-components-analytics.html#description"><i class="fa fa-check"></i><b>5.2</b> Description</a></li>
<li class="chapter" data-level="5.3" data-path="principal-components-analytics.html"><a href="principal-components-analytics.html#the-pca-model"><i class="fa fa-check"></i><b>5.3</b> The PCA model</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="evaluating-predictive-models.html"><a href="evaluating-predictive-models.html"><i class="fa fa-check"></i><b>6</b> Evaluating predictive models</a>
<ul>
<li class="chapter" data-level="6.1" data-path="evaluating-predictive-models.html"><a href="evaluating-predictive-models.html#introduction-1"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="evaluating-predictive-models.html"><a href="evaluating-predictive-models.html#training-testing-and-validation-samples"><i class="fa fa-check"></i><b>6.2</b> Training, Testing, and Validation samples</a></li>
<li class="chapter" data-level="6.3" data-path="evaluating-predictive-models.html"><a href="evaluating-predictive-models.html#evaluating-continuous-versus-discrete-targets"><i class="fa fa-check"></i><b>6.3</b> Evaluating continuous versus discrete targets</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="evaluating-predictive-models.html"><a href="evaluating-predictive-models.html#evaluating-performance-with-continuous-targets"><i class="fa fa-check"></i><b>6.3.1</b> Evaluating performance with continuous targets</a></li>
<li class="chapter" data-level="6.3.2" data-path="evaluating-predictive-models.html"><a href="evaluating-predictive-models.html#evaluating-performance-with-classification-models"><i class="fa fa-check"></i><b>6.3.2</b> Evaluating performance with classification models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="multiple-regression.html"><a href="multiple-regression.html"><i class="fa fa-check"></i><b>7</b> Multiple regression</a>
<ul>
<li class="chapter" data-level="7.1" data-path="multiple-regression.html"><a href="multiple-regression.html#introduction-2"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="multiple-regression.html"><a href="multiple-regression.html#regression-techniques"><i class="fa fa-check"></i><b>7.2</b> Regression techniques</a></li>
<li class="chapter" data-level="7.3" data-path="multiple-regression.html"><a href="multiple-regression.html#regression-for-explanation"><i class="fa fa-check"></i><b>7.3</b> Regression for explanation</a></li>
<li class="chapter" data-level="7.4" data-path="multiple-regression.html"><a href="multiple-regression.html#regression-for-prediction"><i class="fa fa-check"></i><b>7.4</b> Regression for prediction</a>
<ul>
<li class="chapter" data-level="7.4.1" data-path="multiple-regression.html"><a href="multiple-regression.html#revisiting-regression-assumptions"><i class="fa fa-check"></i><b>7.4.1</b> Revisiting regression assumptions</a></li>
<li class="chapter" data-level="7.4.2" data-path="multiple-regression.html"><a href="multiple-regression.html#prediction-example-used-toyota-corollas"><i class="fa fa-check"></i><b>7.4.2</b> Prediction example: Used Toyota Corollas</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="multiple-regression.html"><a href="multiple-regression.html#appendix-a-brief-history-of-regression"><i class="fa fa-check"></i>Appendix: A brief history of regression</a></li>
<li class="chapter" data-level="" data-path="multiple-regression.html"><a href="multiple-regression.html#problems-2"><i class="fa fa-check"></i>Problems</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>8</b> Logistic regression</a>
<ul>
<li class="chapter" data-level="8.1" data-path="logistic-regression.html"><a href="logistic-regression.html#example-with-a-single-predictor"><i class="fa fa-check"></i><b>8.1</b> Example with a single predictor</a></li>
<li class="chapter" data-level="8.2" data-path="logistic-regression.html"><a href="logistic-regression.html#example-predictive-analytic-in-hr"><i class="fa fa-check"></i><b>8.2</b> Example: Predictive analytic in HR</a></li>
<li class="chapter" data-level="8.3" data-path="logistic-regression.html"><a href="logistic-regression.html#predictor-interpretation-and-importance"><i class="fa fa-check"></i><b>8.3</b> Predictor interpretation and importance</a></li>
<li class="chapter" data-level="8.4" data-path="logistic-regression.html"><a href="logistic-regression.html#regularized-logistic-regression"><i class="fa fa-check"></i><b>8.4</b> Regularized logistic regression</a></li>
<li class="chapter" data-level="8.5" data-path="logistic-regression.html"><a href="logistic-regression.html#probability-calibration"><i class="fa fa-check"></i><b>8.5</b> Probability calibration</a></li>
<li class="chapter" data-level="8.6" data-path="logistic-regression.html"><a href="logistic-regression.html#evaluation-of-logistic-regression"><i class="fa fa-check"></i><b>8.6</b> Evaluation of logistic regression</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="ensemble-models.html"><a href="ensemble-models.html"><i class="fa fa-check"></i><b>9</b> Ensemble models</a>
<ul>
<li class="chapter" data-level="9.1" data-path="ensemble-models.html"><a href="ensemble-models.html#creating-ensemble-models"><i class="fa fa-check"></i><b>9.1</b> Creating ensemble models</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="ensemble-models.html"><a href="ensemble-models.html#reduced-variation"><i class="fa fa-check"></i><b>9.1.1</b> Reduced variation</a></li>
<li class="chapter" data-level="9.1.2" data-path="ensemble-models.html"><a href="ensemble-models.html#improved-performance"><i class="fa fa-check"></i><b>9.1.2</b> Improved performance</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="ensemble-models.html"><a href="ensemble-models.html#parallel-and-sequential-learners"><i class="fa fa-check"></i><b>9.2</b> Parallel and sequential learners</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="ensemble-models.html"><a href="ensemble-models.html#bagging-bootstrap-aggregating"><i class="fa fa-check"></i><b>9.2.1</b> Bagging (Bootstrap Aggregating)</a></li>
<li class="chapter" data-level="9.2.2" data-path="ensemble-models.html"><a href="ensemble-models.html#random-forests"><i class="fa fa-check"></i><b>9.2.2</b> Random Forests</a></li>
<li class="chapter" data-level="9.2.3" data-path="ensemble-models.html"><a href="ensemble-models.html#adaboost"><i class="fa fa-check"></i><b>9.2.3</b> AdaBoost</a></li>
<li class="chapter" data-level="9.2.4" data-path="ensemble-models.html"><a href="ensemble-models.html#gradient-boosting-machines"><i class="fa fa-check"></i><b>9.2.4</b> Gradient Boosting Machines</a></li>
<li class="chapter" data-level="9.2.5" data-path="ensemble-models.html"><a href="ensemble-models.html#xgboost"><i class="fa fa-check"></i><b>9.2.5</b> XGBoost</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="ensemble-models.html"><a href="ensemble-models.html#example-of-ensemble-modeling-for-a-continuous-target"><i class="fa fa-check"></i><b>9.3</b> Example of ensemble modeling for a continuous target</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="naive-bayes.html"><a href="naive-bayes.html"><i class="fa fa-check"></i><b>10</b> Naive Bayes</a>
<ul>
<li class="chapter" data-level="10.1" data-path="naive-bayes.html"><a href="naive-bayes.html#a-thought-problem"><i class="fa fa-check"></i><b>10.1</b> A thought problem</a></li>
<li class="chapter" data-level="10.2" data-path="naive-bayes.html"><a href="naive-bayes.html#bayes-theorem-applied-to-predictive-analytics"><i class="fa fa-check"></i><b>10.2</b> Bayes Theorem applied to predictive analytics</a></li>
<li class="chapter" data-level="10.3" data-path="naive-bayes.html"><a href="naive-bayes.html#illustration-of-naïve-bayes-with-a-toy-data-set"><i class="fa fa-check"></i><b>10.3</b> Illustration of Naïve Bayes with a “toy” data set</a></li>
<li class="chapter" data-level="10.4" data-path="naive-bayes.html"><a href="naive-bayes.html#the-assumption-of-conditional-independence"><i class="fa fa-check"></i><b>10.4</b> The assumption of conditional independence</a></li>
<li class="chapter" data-level="10.5" data-path="naive-bayes.html"><a href="naive-bayes.html#naïve-bayes-with-continuous-predictors"><i class="fa fa-check"></i><b>10.5</b> Naïve Bayes with continuous predictors</a></li>
<li class="chapter" data-level="10.6" data-path="naive-bayes.html"><a href="naive-bayes.html#laplace-smoothing"><i class="fa fa-check"></i><b>10.6</b> Laplace Smoothing</a></li>
<li class="chapter" data-level="10.7" data-path="naive-bayes.html"><a href="naive-bayes.html#example-using-naïve-bayes-with-churn-data"><i class="fa fa-check"></i><b>10.7</b> Example using naïve Bayes with churn data</a></li>
<li class="chapter" data-level="10.8" data-path="naive-bayes.html"><a href="naive-bayes.html#spam-detection-using-naïve-bayes"><i class="fa fa-check"></i><b>10.8</b> Spam detection using naïve Bayes</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="deep-learning.html"><a href="deep-learning.html"><i class="fa fa-check"></i><b>11</b> Deep learning</a></li>
<li class="chapter" data-level="12" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html"><i class="fa fa-check"></i><b>12</b> k Nearest Neighbors</a>
<ul>
<li class="chapter" data-level="12.1" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#k-nearest-neighbors-and-memory-based-learning"><i class="fa fa-check"></i><b>12.1</b> k nearest neighbors and memory-based learning</a></li>
<li class="chapter" data-level="12.2" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#typical-applications"><i class="fa fa-check"></i><b>12.2</b> Typical applications</a></li>
<li class="chapter" data-level="12.3" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#what-is-knn"><i class="fa fa-check"></i><b>12.3</b> What is kNN?</a></li>
<li class="chapter" data-level="12.4" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#a-two-dimensional-graphic-example-of-knn"><i class="fa fa-check"></i><b>12.4</b> A two-dimensional graphic example of kNN</a></li>
<li class="chapter" data-level="12.5" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#example-of-knn-diagnosing-heart-disease"><i class="fa fa-check"></i><b>12.5</b> Example of kNN: Diagnosing heart disease</a>
<ul>
<li class="chapter" data-level="12.5.1" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#results"><i class="fa fa-check"></i><b>12.5.1</b> Results</a></li>
</ul></li>
<li class="chapter" data-level="12.6" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#knn-for-continuous-targets"><i class="fa fa-check"></i><b>12.6</b> kNN for continuous targets</a></li>
<li class="chapter" data-level="12.7" data-path="k-nearest-neighbors.html"><a href="k-nearest-neighbors.html#knn-for-multiclass-target-variables"><i class="fa fa-check"></i><b>12.7</b> kNN for multiclass target variables</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="tree-models.html"><a href="tree-models.html"><i class="fa fa-check"></i><b>13</b> Tree models</a>
<ul>
<li class="chapter" data-level="13.1" data-path="tree-models.html"><a href="tree-models.html#classification-trees"><i class="fa fa-check"></i><b>13.1</b> Classification trees</a></li>
<li class="chapter" data-level="13.2" data-path="tree-models.html"><a href="tree-models.html#forming-classification-trees"><i class="fa fa-check"></i><b>13.2</b> Forming classification trees</a></li>
<li class="chapter" data-level="13.3" data-path="tree-models.html"><a href="tree-models.html#varieties-of-classification-tree-algorithms"><i class="fa fa-check"></i><b>13.3</b> Varieties of classification tree algorithms</a></li>
<li class="chapter" data-level="13.4" data-path="tree-models.html"><a href="tree-models.html#criteria-for-splitting-and-growing-a-tree"><i class="fa fa-check"></i><b>13.4</b> Criteria for splitting and growing a tree</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="tree-models.html"><a href="tree-models.html#the-gini-index"><i class="fa fa-check"></i><b>13.4.1</b> The Gini index</a></li>
<li class="chapter" data-level="13.4.2" data-path="tree-models.html"><a href="tree-models.html#information-gain"><i class="fa fa-check"></i><b>13.4.2</b> Information Gain</a></li>
<li class="chapter" data-level="13.4.3" data-path="tree-models.html"><a href="tree-models.html#chi-square-as-a-splitting-criterion"><i class="fa fa-check"></i><b>13.4.3</b> Chi-square as a splitting criterion</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="tree-models.html"><a href="tree-models.html#overfitting"><i class="fa fa-check"></i><b>13.5</b> Overfitting</a></li>
<li class="chapter" data-level="13.6" data-path="tree-models.html"><a href="tree-models.html#example-of-a-classification-tree"><i class="fa fa-check"></i><b>13.6</b> Example of a classification tree</a></li>
<li class="chapter" data-level="13.7" data-path="tree-models.html"><a href="tree-models.html#regression-trees"><i class="fa fa-check"></i><b>13.7</b> Regression trees</a>
<ul>
<li class="chapter" data-level="13.7.1" data-path="tree-models.html"><a href="tree-models.html#how-regression-trees-work"><i class="fa fa-check"></i><b>13.7.1</b> How regression trees work</a></li>
<li class="chapter" data-level="13.7.2" data-path="tree-models.html"><a href="tree-models.html#example-predicting-home-prices"><i class="fa fa-check"></i><b>13.7.2</b> Example: Predicting home prices</a></li>
</ul></li>
<li class="chapter" data-level="13.8" data-path="tree-models.html"><a href="tree-models.html#strengths-and-weaknesses"><i class="fa fa-check"></i><b>13.8</b> Strengths and weaknesses</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="neural-networks.html"><a href="neural-networks.html"><i class="fa fa-check"></i><b>14</b> Neural networks</a>
<ul>
<li class="chapter" data-level="14.1" data-path="neural-networks.html"><a href="neural-networks.html#what-are-artificial-neural-networks"><i class="fa fa-check"></i><b>14.1</b> What are artificial neural networks?</a>
<ul>
<li class="chapter" data-level="14.1.1" data-path="neural-networks.html"><a href="neural-networks.html#human-neurons-to-mathematical-models"><i class="fa fa-check"></i><b>14.1.1</b> Human neurons to mathematical models</a></li>
<li class="chapter" data-level="14.1.2" data-path="neural-networks.html"><a href="neural-networks.html#activation-functions"><i class="fa fa-check"></i><b>14.1.2</b> Activation functions</a></li>
</ul></li>
<li class="chapter" data-level="14.2" data-path="neural-networks.html"><a href="neural-networks.html#the-road-to-machine-learning-with-neural-nets"><i class="fa fa-check"></i><b>14.2</b> The road to machine learning with neural nets</a></li>
<li class="chapter" data-level="14.3" data-path="neural-networks.html"><a href="neural-networks.html#example-of-a-neural-network"><i class="fa fa-check"></i><b>14.3</b> Example of a neural network</a></li>
<li class="chapter" data-level="14.4" data-path="neural-networks.html"><a href="neural-networks.html#training-a-neural-net"><i class="fa fa-check"></i><b>14.4</b> Training a neural net</a></li>
<li class="chapter" data-level="14.5" data-path="neural-networks.html"><a href="neural-networks.html#considerations-in-using-neural-nets"><i class="fa fa-check"></i><b>14.5</b> Considerations in using neural nets</a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="neural-networks.html"><a href="neural-networks.html#missing-data"><i class="fa fa-check"></i><b>14.5.1</b> Missing data</a></li>
<li class="chapter" data-level="14.5.2" data-path="neural-networks.html"><a href="neural-networks.html#representative-data"><i class="fa fa-check"></i><b>14.5.2</b> Representative data</a></li>
<li class="chapter" data-level="14.5.3" data-path="neural-networks.html"><a href="neural-networks.html#all-eventualities-must-be-covered"><i class="fa fa-check"></i><b>14.5.3</b> All eventualities must be covered</a></li>
<li class="chapter" data-level="14.5.4" data-path="neural-networks.html"><a href="neural-networks.html#unbalanced-data-sets"><i class="fa fa-check"></i><b>14.5.4</b> Unbalanced data sets</a></li>
<li class="chapter" data-level="14.5.5" data-path="neural-networks.html"><a href="neural-networks.html#the-overfitting-problem"><i class="fa fa-check"></i><b>14.5.5</b> The overfitting problem</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="neural-networks.html"><a href="neural-networks.html#neural-network-example"><i class="fa fa-check"></i><b>14.6</b> Neural network example</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="cluster-analysis.html"><a href="cluster-analysis.html"><i class="fa fa-check"></i><b>15</b> Cluster analysis</a>
<ul>
<li class="chapter" data-level="15.1" data-path="cluster-analysis.html"><a href="cluster-analysis.html#approaches-to-forming-clusters"><i class="fa fa-check"></i><b>15.1</b> Approaches to forming clusters</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="cluster-analysis.html"><a href="cluster-analysis.html#hierarchical-versus-partitioning-methods"><i class="fa fa-check"></i><b>15.1.1</b> Hierarchical versus partitioning methods</a></li>
<li class="chapter" data-level="15.1.2" data-path="cluster-analysis.html"><a href="cluster-analysis.html#hard-versus-soft-methods"><i class="fa fa-check"></i><b>15.1.2</b> “Hard” versus “soft” methods</a></li>
<li class="chapter" data-level="15.1.3" data-path="cluster-analysis.html"><a href="cluster-analysis.html#applying-hierarchical-clusters"><i class="fa fa-check"></i><b>15.1.3</b> Applying hierarchical clusters</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Analytics with KNIME and R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="references" class="section level1 unnumbered">
<h1>References</h1>

<div id="refs" class="references csl-bib-body hanging-indent">
<div class="csl-entry">
<span>“2020 Retention Report.”</span> 2020. Work Institute. https://doi.org/<a href="https://doi.org/&quot; &quot; ">" "</a>.
</div>
<div class="csl-entry">
Adebayo, Samuel. 2020. <span>“How to Solve a Problem.”</span> https://dataaspirant.com.
</div>
<div class="csl-entry">
Aggarwal, Charu C. 2017. <em>Outlier Analysis, Second Edition</em>. Switzerland: Springer International Publishing.
</div>
<div class="csl-entry">
Aha, David W. 1988. <span>“Heart Disease Data Set.”</span> https://archive.ics.uci.edu/ml/datasets/heart+disease.
</div>
<div class="csl-entry">
Amelia. 2021. <span>“A Program for Missing Data.”</span> https://cran.r-project.org/web/packages/Amelia/Amelia.pdf.
</div>
<div class="csl-entry">
Arnuld. 2020. <span>“Some Key Things i Learned from Google’s " Introduction to Machine Learning Problem Framing" MOOC.”</span> https://www.linkedin.com/pulse/some-key-things-i-learned-from-googles-introduction-machine-on-data.
</div>
<div class="csl-entry">
Azen, Razia, and Nicole Traxel. 2009. <span>“Using Dominance Analysis to Determine Predictor Importance in Logistic Regression.”</span> <em>Journal of Educational and Behavioral Statistics</em> 34: 319–47.
</div>
<div class="csl-entry">
Bramer, Max. 2007. <em>Principles of Data Mining</em>. New York: Springer.
</div>
<div class="csl-entry">
Breiman, JH Friedman, L., and CJ Stone. 1984. <em>Classification and Regression Trees</em>. Boca Raton: Chapman; Hall/CRC.
</div>
<div class="csl-entry">
Breiman, Leo. 1966. <span>“Bagging Predictors.”</span> <em>Machine Learning</em>, 123–40.
</div>
<div class="csl-entry">
———. 2001. <span>“Statistical Modeling: The Two Cultures.”</span> <em>Statistical Science</em>, 199–215.
</div>
<div class="csl-entry">
Brownlee, Jason. 2020. <span>“Why Use Ensemble Learning?”</span> https://machinelearningmastery.com/why-use-ensemble-learning/.
</div>
<div class="csl-entry">
Cady, Field. 2017. <em>The Data Science Handbook</em>. Hoboken, NJBoca Raton: John Wiley; Sons.
</div>
<div class="csl-entry">
Cansiz, Sergen. 2020. <span>“Mahalanobis Distance and Multivariate Outlier Detection in r.”</span> https://towardsdatascience.com/mahalonobis-distance-and-outlier-detection-in-r-cb9c37576d7d.
</div>
<div class="csl-entry">
Chen, Tianqi, and Carlos Guestrin. 1996. <span>“XGBoost: A Scalable Tree Boosting System.”</span> In <em>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</em>, 785–94. https://dl.acm.org/doi/10.1145/2939672.2939785.
</div>
<div class="csl-entry">
ChristianSalas-Eljatiba, Timothy G. Gregoireb, AndresFuentes-Ramireza, and ValeskaYaitul. 2018. <span>“A Study on the Effects of Unbalanced Data When Fitting Logistic Regression Models in Ecology.”</span> <em>Ecological Indicators</em>, 502–8.
</div>
<div class="csl-entry">
Clissold, Rachel. 2021. <span>“How to Solve a Problem.”</span> https://www.wikihow.com/Solve-a-Problem.
</div>
<div class="csl-entry">
Cox, D. R. 2001. <span>“Comment on: Statistical Modeling: The Two Cultures.”</span> <em>Statistical Science</em>, 216–18.
</div>
<div class="csl-entry">
<span>“CRISP-DM, Still the Top Methodology for Analytics, Data Mining, or Data Science Projects.”</span> n.d. <a href="https://www.kdnuggets.com/2014/10/crisp-dm-top-methodology-analytics-data-mining-data-science-projects.html#:~:text=CRISP%2DDM%20remains%20the%20most,CRISP%2DDM%20is%20long%20overdue">https://www.kdnuggets.com/2014/10/crisp-dm-top-methodology-analytics-data-mining-data-science-projects.html#:~:text=CRISP%2DDM%20remains%20the%20most,CRISP%2DDM%20is%20long%20overdue</a>.
</div>
<div class="csl-entry">
Davenport, Thomas H., and Jinho Kim. 2013. <em>Keeping up with the Quants: Your Guide to Understanding and Using Analytics</em>. Boston: Harvard Business Review Press.
</div>
<div class="csl-entry">
DeRusha, Karen, and Bill WOlfson. n.d. <span>“Shift Your Lens: The Power of Re-Framing Problems.”</span> http://www.integratingengineering.org/workbook/documents/Problem.
</div>
<div class="csl-entry">
Efron, B. 2001. <span>“Comment on: Statistical Modeling: The Two Cultures.”</span> <em>Statistical Science</em>, 218–19.
</div>
<div class="csl-entry">
———. 2020. <span>“Prediction, Estimation, and Attribution.”</span> <em>International Statistical Review</em>, S28–59.
</div>
<div class="csl-entry">
Elkan, Charles. 2001. <span>“The Foundations of Cost-Sensitive Learning.”</span> In <em>Proceedings of the Seventeenth International Joint Conference on Artificial Intelligence</em>. http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=B24CDCB3FA2EBC3A4D5AEB2B35160B90?doi=10.1.1.29.514&amp;rep=rep1&amp;type=pdf.
</div>
<div class="csl-entry">
Ellenberg, Jordan. 2016. <span>“Abraham Wald and the Missing Bullet Holes.”</span> https://medium.com/@penguinpress/an-excerpt-from-how-not-to-be-wrong-by-jordan-ellenberg-664e708cfc3d.
</div>
<div class="csl-entry">
Everitt, Sabine Landau, Brian S. 2011. <em>Cluster Analysis</em>. John Wiley.
</div>
<div class="csl-entry">
Flinchbaugh, Jamie. 2009. <span>“Leading Lean: Solve the Right Problem.”</span> https://www.assemblymag.com/articles/86658-leading-lean-solve-the-right-problem.
</div>
<div class="csl-entry">
Freund, Yoav, and Robert E. Schapire. 1996. <span>“Experiments with a New Boosting Algorithm.”</span> In <em>Machine Learning: Proceedings of the Thirteenth International Conference</em>. https://cseweb.ucsd.edu// yfreund/papers/boostingexperiments.pdf.
</div>
<div class="csl-entry">
Friedman, Jerome. 2001. <span>“Greedy Function Approximation: A Gradient Boosting Machine.”</span> <em>Annals of Statistics</em>, 1189–1232.
</div>
<div class="csl-entry">
———. 2002. <span>“Stochastic Gradient Boosting.”</span> <em>Computational Statistics &amp; Data Analysis</em>, 367–78.
</div>
<div class="csl-entry">
Gartner. n.d. <span>“Analytics.”</span> https://www.gartner.com/en/information-technology/glossary/analytics.
</div>
<div class="csl-entry">
Gromping, U. 2019a. <span>“South German Credit Data: Correcting a Widely Used Data Set.”</span> http://www1.beuth-hochschule.de/FB_II/reports/Report-2019-004.pdf.
</div>
<div class="csl-entry">
———. 2019b. <span>“South German Credit (UPDATE) Data Set.”</span> https://archive.ics.uci.edu/ml/datasets/South+German+Credit+.
</div>
<div class="csl-entry">
Harmouch, Mahmoud. n.d. <span>“17 Clustering Algorithms Used in Data Science and Mining.”</span> https://towardsdatascience.com/17-clustering-algorithms-used-in-data-science-mining-49dbfa5bf69a.
</div>
<div class="csl-entry">
Hastie, Robert Tibshirani Jerome Friedman, Trevor. 2009. <em>The Elements of Statistical Learning</em>. Springer International.
</div>
<div class="csl-entry">
Hauch, Brian. 2018. <span>“Finding the True North of a Problem: Problem-Framing Principles for Design-Led Innovation.”</span> https://medium.com/nyc-design/finding-the-true-north-of-a-problem-problem-framing-principles-for-design-led-innovation-b0c7620317bf.
</div>
<div class="csl-entry">
Hotelling, H. 1933. <span>“Analysis of a Complex of Statistical Variables into Principal Components.”</span> <em>Journal of Educational Psychology</em>, 417 - 441 and 498-520.
</div>
<div class="csl-entry">
<span>“Hr—Analytics-Employee-Turnover.”</span> n.d. Work Institute. https://doi.org/<a href="https://doi.org/&quot; &quot;   ">" "</a>.
</div>
<div class="csl-entry">
Ittner, Christopher. 2019. <span>“How Digital Technology Is Transforming Cost Management.”</span> https://knowledge.wharton.upenn.edu/article/cost-management-in-the-digital-age/.
</div>
<div class="csl-entry">
Jaspreet. 2016. <span>“A Concise History of Neural Networks.”</span> https://towardsdatascience.com/a-concise-history-of-neural-networks-2070655d3fec.
</div>
<div class="csl-entry">
Jonassen, David. 1997. <span>“Instructional Design Models for Well-Structured and Ill-Structured Problem-Solving Learning Outcomes.”</span> <em>Educational Technology Research and Development</em>, 65–94.
</div>
<div class="csl-entry">
Karimovich, Khamidov Sherzod Jaloldin ugli, Ganiev Salim, and Olimov Iskandar Salimbayevich. 2020. <span>“Analysis of Machine Learning Methods for Filtering Spam Messages in Email Services.”</span> In <em>Proceedings of the 22nd International Conference on Machine Learning</em>, 625–32.
</div>
<div class="csl-entry">
<span>“KDD and Data Mining.”</span> n.d. <a href="https://www.datascience-pm.com/kdd-and-data-mining/">https://www.datascience-pm.com/kdd-and-data-mining/</a>.
</div>
<div class="csl-entry">
KNIME. 2020. <span>“KNIME Workbench Guide.”</span> https://docs.knime.com/2018-12/analytics_platform_workbench_guide/index.html#workspaces.
</div>
<div class="csl-entry">
Kuhn, Max, and Kjell Johnson. 2016. <em>Applied Predictive Modeling</em>. 2nd ed. New York: Springer.
</div>
<div class="csl-entry">
Kunapuli, Gautam. 2021. <em>Ensembles for Machine Learning</em>. Manning Publications.
</div>
<div class="csl-entry">
Long, J. Scott, and Jeremy Frees. 2006. <em>Regression Models for Categorical Dependent Variables Using Stata</em>. 2nd ed. College Station, Texas: Chapman; Hall/CRC.
</div>
<div class="csl-entry">
Ma, Kunihito Yamamori, Thae Ma, and Aye Thida. 2020. <span>“A Comparative Approach to Naïve Bayes Classifier and Support Vector Machine for Email Spam Classification.”</span> In <em>IEEE 9th Global Conference on Consumer Electronics</em>.
</div>
<div class="csl-entry">
McCulloch, Warren S., and Walter H. Pitts. 1943. <span>“A Logical Calculus of the Ideas Immanent in Nervous Activity.”</span> <em>Bulletin of Mathematical Biophysics</em>, 114–33.
</div>
<div class="csl-entry">
mice. 2021. <span>“Multivariate Imputation by Chained Equations.”</span> https://cran.r-project.org/web/packages/mice/mice.pdf.
</div>
<div class="csl-entry">
Minsky, Marvin, and Seymour Papert. 1969. <em>Perceptrons: An Introduction to Computational Geometry</em>. Cambridge, Mass.: MIT Press.
</div>
<div class="csl-entry">
mlr. 2021. <span>“Machine Learning in r.”</span> https://cran.r-project.org/web/packages/mlr/mlr.pdf.
</div>
<div class="csl-entry">
mvoutlier. 2021. <span>“Multivariate Outlier Detection Based on Robust Methods.”</span> https://cran.r-project.org/web/packages/mvoutlier/mvoutlier.pdf.
</div>
<div class="csl-entry">
Natekin, Alexey, and Alois Knoll. 2013. <span>“Greedy Function Approximation: A Gradient Boosting Machine Tutorial.”</span> <em>Frontiers in Neurorobotics</em>, 1189–1232.
</div>
<div class="csl-entry">
Nielsen, Michael. 2019. <span>“Neural Networks and Deep Learning.”</span> http://neuralnetworksanddeeplearning.com/.
</div>
<div class="csl-entry">
Pearson, Karl. 1902. <span>“On Lines and Planes of Closest Fit to Systems of Points in Space.”</span> <em>Philosophical Magazine</em>, 559–72.
</div>
<div class="csl-entry">
<span>“Play Tennis: Simple Dataset with Decisions about Playing Tennis.”</span> n.d. <a href="https://www.coursera.org/learn/machine-learning-under-the-hood">https://www.coursera.org/learn/machine-learning-under-the-hood</a>.
</div>
<div class="csl-entry">
Rubin, Donald B. 1976. <span>“Inference and Missing Data.”</span> <em>Biometrika</em> 63: 581–90.
</div>
<div class="csl-entry">
Sarker, Iqbal H. 2021. <span>“Deep Learning: A Comprehensive Overview on Techniques, Taxonomy, Applications and Research Directions.”</span> <em>SN Computer Science</em>.
</div>
<div class="csl-entry">
Seelig, Tina. 2013. <span>“Shift Your Lens: The Power of Re-Framing Problems.”</span> http://stvp.stanford.edu/blog/?p=6435.
</div>
<div class="csl-entry">
<span>“SEMMA from SAS.”</span> n.d. <a href="https://documentation.sas.com/doc/en/emref/14.3/n061bzurmej4j3n1jnj8bbjjm1a2.htm">https://documentation.sas.com/doc/en/emref/14.3/n061bzurmej4j3n1jnj8bbjjm1a2.htm</a>.
</div>
<div class="csl-entry">
Seni, Giovanni, and John F. Elder. 2010. <em>Ensemble Methods in Data Mining: Improving Accuracy Through Combining Predictions</em>. Morgan &amp; Claypool Publishers.
</div>
<div class="csl-entry">
Shlens, Jon. 2003. <span>“A Tutorial on Principal Component Analysis.”</span> https://www.cs.princeton.edu/picasso/mats/PCA-Tutorial-Intuition_jp.pdf.
</div>
<div class="csl-entry">
Shmueli, Galit. 2010. <span>“To Explain or Predict.”</span> <em>Statistical Science</em>, 289–310.
</div>
<div class="csl-entry">
Shoemaker, Paul J. H., and J. Edward Russo. 2001. <span>“Knitr: Manging Frames to Make Better Decisions.”</span> In <em>Wharton on Making Decisions</em>, edited by Howard C. Kunreuther Hoch Stephen J. and Robert E. Gunther. John Wiley.
</div>
<div class="csl-entry">
SMOTE. 2019. <span>“A Collection of Oversampling Techniques for Class Imbalance Problem Based on SMOTE.”</span> https://cran.r-project.org/web/packages/smotefamily/smotefamily.pdf.
</div>
<div class="csl-entry">
<span>“SMS Spam Collection Data Set, UCI Machine Learning Repository.”</span> n.d. <a href="https://archive.ics.uci.edu/ml/datasets/sms+spam+collection">https://archive.ics.uci.edu/ml/datasets/sms+spam+collection</a>.
</div>
<div class="csl-entry">
<span>“Spam Statistics and Facts.”</span> n.d. <a href="https://www.spamlaws.com/spam-stats.html">https://www.spamlaws.com/spam-stats.html</a>.
</div>
<div class="csl-entry">
Stanton, Jeffrey M. 2001. <span>“Galton, Pearson, and the Peas: A Brief History of Linear Regression for Statistics Instructors.”</span> <em>Journal of Statistics Education</em>, S28–59.
</div>
<div class="csl-entry">
Surowiecki, James. 2004. <em>The Wisdom of Crowds: Why the Many Are Smarter Than the Few and How Collective Wisdom Shapes Business, Economies, Societies and Nations</em>. Doubleday; Anchor.
</div>
<div class="csl-entry">
Taylor, James. 2017. <span>“Bringing Business Clarity to CRISP-DM.”</span> https://www.kdnuggets.com/2017/01/business-clarity-crisp-dm.html.
</div>
<div class="csl-entry">
<span>“The Crisp-DM User Guide.”</span> n.d. <a href="https://s2.smu.edu/~mhd/8331f03/crisp.pdf">https://s2.smu.edu/~mhd/8331f03/crisp.pdf</a>.
</div>
<div class="csl-entry">
<span>“Top 10 Machine Learning Algorithms You Should Know in 2021.”</span> n.d. <a href="https://www.simplilearn.com/10-algorithms-machine-learning-engineers-need-to-know-article">https://www.simplilearn.com/10-algorithms-machine-learning-engineers-need-to-know-article</a>.
</div>
<div class="csl-entry">
Tukey, John. 1977. <em>Exploratory Data Analysis</em>. Addison-Wesley.
</div>
<div class="csl-entry">
Unal, Hamit Taner, and Fatih Başçiftci. 2021. <span>“Evolutionary Design of Neural Network Architectures: A Review of Three Decades of Research.”</span> https://link.springer.com/article/10.1007/s10462-021-10049-5.
</div>
<div class="csl-entry">
Vázquez, Favio. 2018. <span>“A Conversation about Deep Learning.”</span> https://towardsdatascience.com/a-conversation-about-deep-learning-9a915983107.
</div>
<div class="csl-entry">
VIM. 2021. <span>“Visualization and Imputation of Missing Values.”</span> https://cran.r-project.org/web/packages/VIM/VIM.pdf.
</div>
<div class="csl-entry">
<span>“What Is TDSP?”</span> n.d. <a href="https://www.datascience-pm.com/tdsp/">https://www.datascience-pm.com/tdsp/</a>.
</div>
<div class="csl-entry">
Widmann, Maarit. n.d. <span>“Cohen’s Kappa: What It Is, When to Use It, and How to Avoid Its Pitfalls.”</span> <a href="https://thenewstack.io/cohens-kappa-what-it-is-when-to-use-it-and-how-to-avoid-its-pitfalls/#:~:text=Cohen&#39;s%20kappa%20is%20a%20metric,performance%20of%20a%20classification%20model.&amp;text=Like%20many%20other%20evaluation%20metrics,based%20on%20the%20confusion%20matrix">https://thenewstack.io/cohens-kappa-what-it-is-when-to-use-it-and-how-to-avoid-its-pitfalls/#:~:text=Cohen's%20kappa%20is%20a%20metric,performance%20of%20a%20classification%20model.&amp;text=Like%20many%20other%20evaluation%20metrics,based%20on%20the%20confusion%20matrix</a>.
</div>
<div class="csl-entry">
<span>“Wolfram MathWord: Stirling Numbers of the Second Kind.”</span> n.d. <a href="https://https://mathworld.wolfram.com/StirlingNumberoftheSecondKind.html">https://https://mathworld.wolfram.com/StirlingNumberoftheSecondKind.html</a>.
</div>
</div>
</div>




















            </section>

          </div>
        </div>
      </div>
<a href="cluster-analysis.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["TextbookDraft.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
